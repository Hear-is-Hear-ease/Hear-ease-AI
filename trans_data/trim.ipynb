{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "import wave\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/jaewone/developer/tensorflow/baby-cry-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constant.os import *\n",
    "from utils.os import *\n",
    "from utils.sound import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav 파일을 읽어온다.\n",
    "with wave.open(\"/Users/jaewone/Downloads/hungry_9.wav\", \"r\") as file:\n",
    "    params = file.getparams()\n",
    "    n_channels, sampwidth, framerate, n_frames = params[:4]\n",
    "    audio_data = file.readframes(n_frames)\n",
    "    wave_data = np.frombuffer(audio_data, dtype=np.int16)\n",
    "\n",
    "# 오디오 시그널을 통한 에너지 계산\n",
    "energy = np.abs(wave_data)\n",
    "\n",
    "# 백색 잡음을 분류하기 위한 임계값을 설정.\n",
    "# 전체 에너지의 하위 10%에 10을 곱하여 임계값을 설정하였으나 추가적은 고민이 필요하다.\n",
    "threshold = np.percentile(energy, 10) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36003, 274324)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detect_non_silence(audio_data, threshold, frame_size):\n",
    "    \"\"\"\n",
    "    오디오 신호에서 무음이 아닌 섹션의 시작과 끝을 감지한다.\n",
    "    \n",
    "    Parameters:\n",
    "        - audio_data (numpy.array): 묵음을 감지해야 하는 오디오 데이터.\n",
    "        - threshold (float): 오디오가 무음으로 간주되는 에너지 임계값.\n",
    "        - frame_size (int): 오디오 에너지의 이동 평균을 계산하기 위해 고려할 샘플 수.\n",
    "    \n",
    "    Returns:\n",
    "        - start (int): 비침묵 섹션의 시작 샘플.\n",
    "        - end (int): non-silence 섹션의 엔딩 샘플.\n",
    "    \"\"\"\n",
    "    \n",
    "    moving_avg = np.convolve(audio_data, np.ones((frame_size,))/frame_size, mode='valid')\n",
    "    non_silence = np.where(moving_avg > threshold)[0]\n",
    "\n",
    "    start = non_silence[0]\n",
    "    end = non_silence[-1] + frame_size  # compensate for the 'valid' mode in convolution\n",
    "\n",
    "    return start, end\n",
    "\n",
    "# Use a larger frame size to get a moving average of the audio energy\n",
    "frame_size = 5000\n",
    "start, end = detect_non_silence(energy, threshold, frame_size)\n",
    "trimmed_wave_data_2 = wave_data[start:end]\n",
    "\n",
    "start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jaewone/Downloads/hungry_9_trimmed_me.wav'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trim된 numpy array를 wav 파일로 저장한다.\n",
    "output_path_2 = \"/Users/jaewone/Downloads/hungry_9_trimmed_me.wav\"\n",
    "with wave.open(output_path_2, \"w\") as out_file:\n",
    "    out_file.setparams(params)\n",
    "    out_file.writeframes(trimmed_wave_data_2.tobytes())\n",
    "\n",
    "output_path_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
