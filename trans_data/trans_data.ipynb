{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원본 데이터로부터 모델 학습에 사용할 수 있는 데이터를 추출해보자.\n",
    "\n",
    "프로세싱 순서는 아래와 같다.\n",
    "\n",
    "1. 사용할 수 없는 데이터는 제외한 다음 상위 7개의 state를 가지는 음성만을 가져온다. \n",
    "\n",
    "2. sample rate를 16000으로 통일한다.\n",
    "\n",
    "3. 파일의 이름을 통해 state를 설정하기 위해 파일 이름을 모두 변경한다.\n",
    "\n",
    "4. 음성 파일 앞뒤의 화이트 노이즈(또는 특정 임계값 이하의 에너지를 가지는 시점)를 제거한다.\n",
    "\n",
    "5. 음성이 5초 단위로 분할하여 모두 동일한 길이를 가지도록 조정한다.\n",
    "\n",
    "6. 음성의 노이즈를 제거한다.\n",
    "\n",
    "7. 음성의 유사도를 분석하여 가장 유사한 n개의 데이터만 사용한다.\n",
    "\n",
    "8. 모델의 학습 데이터로 사용한다.\n",
    "\n",
    "> 4번 과정 대신 get_sample_data를 통해 임의로 n개의 파일을 선택해 학습을 수행하는 방법 또한 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set project path : 본인의 프로젝트가 있는 절대 경로를 append를 통해 추가한다.\n",
    "main_path = '/Users/jaewone/developer/tensorflow/baby-cry-classification'\n",
    "\n",
    "sys.path.append(main_path)\n",
    "data_path = os.path.join(main_path, 'data')\n",
    "sample_data_path = os.path.join(data_path, 'sample_data')\n",
    "csv_path = os.path.join(main_path, 'info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custon packages\n",
    "from utils.os import *\n",
    "from utils.sound import *\n",
    "from trans_data.bit_sampling import *\n",
    "from trans_data.get_state_list import get_state_list_from_dir_name\n",
    "from trans_data.create_state_folder import create_state_folder\n",
    "from trans_data.rename_by_state import rename_files_by_state\n",
    "from trans_data.trim_white_noise import trim_audio\n",
    "from trans_data.split_audio import split_audio_list_in_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 3688개의 데이터 중 사용할 수 없는 216개의 데이터가 제외되었다.\n"
     ]
    }
   ],
   "source": [
    "# 1. 사용할 수 없는 데이터는 제외한 다음 상위 7개의 state를 가지는 음성만을 가져온다. \n",
    "# 2. sample rate를 16000으로 통일한다.\n",
    "create_state_folder(main_path, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 파일의 이름을 통해 state를 설정하기 위해 파일 이름을 모두 변경한다.\n",
    "file_list = rename_files_by_state(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3238/3238 [24:09<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trimming에 실패한 5개의 파일이 삭제됨.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. 음성 파일 앞뒤의 화이트 노이즈(또는 특정 임계값 이하의 에너지를 가지는 시점)를 제거한다.\n",
    "failed_file_list = []\n",
    "for i in tqdm(range(len(file_list))):\n",
    "    try:\n",
    "        trim_audio(file_list[i], inplace=True)\n",
    "    except:\n",
    "        failed_file_list.append(file_list[i])\n",
    "\n",
    "print(f'trimming에 실패한 {len(failed_file_list)}개의 파일이 삭제됨.')\n",
    "for file in failed_file_list:\n",
    "    file_list.remove(file)\n",
    "    remove_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 음성이 5초 단위로 분할하여 모두 동일한 길이를 가지도록 조정한다.\n",
    "split_audio_list = split_audio_list_in_sec(file_list, 5, inplace=True)\n",
    "\n",
    "# renaming\n",
    "file_list = rename_files_by_state(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaewone/ENTER/envs/tf25/lib/python3.9/site-packages/numba/cpython/hashing.py:482: UserWarning: FNV hashing is not implemented in Numba. See PEP 456 https://www.python.org/dev/peps/pep-0456/ for rationale over not using FNV. Numba will continue to work, but hashes for built in types will be computed using siphash24. This will permit e.g. dictionaries to continue to behave as expected, however anything relying on the value of the hash opposed to hash as a derived property is likely to not work as expected.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0    5828\n",
      "Name: duration, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>diaper</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sleepy</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awake</td>\n",
       "      <td>711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hug</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hungry</td>\n",
       "      <td>1119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sad</td>\n",
       "      <td>1222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           state  file\n",
       "0         diaper   596\n",
       "1  uncomfortable   643\n",
       "2         sleepy   693\n",
       "3          awake   711\n",
       "4            hug   844\n",
       "5         hungry  1119\n",
       "6            sad  1222"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임을 생성하여 파일을 분석해보자.\n",
    "df = pd.DataFrame({'file':file_list})\n",
    "df['duration'] = df['file'].apply(lambda file: get_duration(file))\n",
    "df['file'] = df['file'].apply(lambda file: file.rsplit('/', 1)[1])\n",
    "df['state'] = df['file'].apply(lambda file: file.split('_', 1)[0]).astype('category')\n",
    "\n",
    "# 모든 파일들은 5초의 값을 가짐을 확인할 수 있다.\n",
    "# diaper이 596개로 가장 적게 존재하며 sad가 1222개로 가장 많이 존재한다.\n",
    "count_by_state = df[['file', 'state']].groupby('state').count().reset_index().sort_values('file').reset_index(drop=True)\n",
    "print(df['duration'].value_counts())\n",
    "count_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 음성의 노이즈를 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1222/1222 [03:36<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State sad Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 844/844 [01:41<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State hug Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 596/596 [00:50<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State diaper Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 1119/1119 [03:00<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State hungry Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 693/693 [01:11<00:00,  9.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State sleepy Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 711/711 [01:12<00:00,  9.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State awake Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 643/643 [00:59<00:00, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State uncomfortable Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. 음성의 유사도를 분석하여 가장 유사한 n개의 데이터만 사용한다.\n",
    "# 위 5번 과정을 통해 가장 적은 자료 state의 개수는 596개(diaper)이였음으로 이의 상위 90%인 540개만 사용하겠다.\n",
    "\n",
    "def delete_dissimilar_wavs(data_path:str, n_limit:int):\n",
    "  state_list = ['sad', 'hug', 'diaper', 'hungry', 'sleepy', 'awake', 'uncomfortable']\n",
    "  for state in state_list:\n",
    "      state_path = os.path.join(data_path, state)\n",
    "      state_file_list = [os.path.join(state_path, file) for file in os.listdir(state_path)]\n",
    "\n",
    "      # get similarities\n",
    "      sim_file_list = get_similarities(state_file_list)\n",
    "\n",
    "      # 상위 540를 제외하고 모두 제거한다.\n",
    "      del_file_list = sim_file_list[n_limit:]\n",
    "      for file in del_file_list:\n",
    "          remove_file(file)\n",
    "      print(f'State {state} Done.\\n')\n",
    "\n",
    "delete_dissimilar_wavs(data_path, 540)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용을 완료한 info.csv는 제거한다.\n",
    "remove_file(csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
