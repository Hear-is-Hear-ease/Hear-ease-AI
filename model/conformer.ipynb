{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conformer(CNN + Transfomer) 모델을 이용해 영아 울음소리 분류 모델을 만들어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conformer 논문: https://arxiv.org/pdf/2005.08100.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "import sys\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Activation, Dropout, Add, TimeDistributed, Multiply, Conv1D, Conv2D, MaxPooling1D, AveragePooling1D\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/jaewone/developer/tensorflow/baby-cry-classification')\n",
    "\n",
    "from utils.sound import *\n",
    "from utils.os import *\n",
    "from constant.os import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_path = os.path.join(main_path, 'sample_data')\n",
    "info_csv_path = os.path.join(main_path, 'sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 음성 파일 경로와 클래스 레이블 지정\n",
    "df = pd.read_csv(info_csv_path, index_col=0)\n",
    "audio_files = [os.path.join(sample_data_path, file) for file in df['file']]\n",
    "class_labels = df['state'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaewone/ENTER/envs/tf25/lib/python3.9/site-packages/numba/cpython/hashing.py:482: UserWarning: FNV hashing is not implemented in Numba. See PEP 456 https://www.python.org/dev/peps/pep-0456/ for rationale over not using FNV. Numba will continue to work, but hashes for built in types will be computed using siphash24. This will permit e.g. dictionaries to continue to behave as expected, however anything relying on the value of the hash opposed to hash as a derived property is likely to not work as expected.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 멜 스펙트럼과 클래스 레이블 추출\n",
    "def compute_mel_spectrogram(audio_path, n_fft=2048, hop_length=512, n_mels=128):\n",
    "    \"\"\"\n",
    "    멜 스펙트럼을 계산하는 함수\n",
    "\n",
    "    Parameters:\n",
    "        audio_path (str): 오디오 파일 경로\n",
    "        n_fft (int): FFT(Fast Fourier Transform) 창의 크기 (default: 2048)\n",
    "        hop_length (int): 이동 크기 (default: 512)\n",
    "        n_mels (int): 멜 밴드의 수 (default: 128)\n",
    "\n",
    "    Returns:\n",
    "        mel_spectrogram (ndarray): 계산된 멜 스펙트럼\n",
    "        sr (int): 오디오의 샘플링 레이트(초당 추출하는 샘플링 개수)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 오디오 파일 불러오기 | audio.shape==(55680,) | sr=8000\n",
    "    audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "    # 멜 스펙트럼 계산(y에 대한 멜 스펙트럼을 계산) | mel_spectrogram.shape=(128,109)\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "\n",
    "    # 로그 스케일 변환: 이를 통해 스펙트럼의 에너지를 더 쉽게 관찰하고, 시각화할 수 있다.\n",
    "    # ref=np.max는 로그 변환 시 사용되는 기준값을 의미하며, 여기서는 스펙트럼 값 중 가장 큰 값으로 정규화한다.\n",
    "    # mel_spectrogram.shape=(128,109)\n",
    "    # 128이 세로이고 음석파일의 길이에 따라 가로 길이(두번째 숫자)가 길어지는 것 같다.\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "\n",
    "    return mel_spectrogram, sr\n",
    "\n",
    "\n",
    "def extract_features_and_labels(audio_files, class_labels):\n",
    "    features, labels = [], []\n",
    "    for file, label in zip(audio_files, class_labels):\n",
    "        mel_spectrogram, _ = compute_mel_spectrogram(file)\n",
    "        features.append(mel_spectrogram)\n",
    "        labels.append(label)\n",
    "\n",
    "    # [(128,109), (128, 109), (128, 108), (129, 110), ...]\n",
    "    # max: (128, 109) | min: (128, 102)\n",
    "    for i in range(len(features)):\n",
    "        features[i] = np.array([feature[:102] for feature in features[i]])\n",
    "\n",
    "    # 신경망 모델을 위해 데이터 변환\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "X, y = extract_features_and_labels(audio_files, class_labels)\n",
    "\n",
    "# 클래스 레이블 인코딩 및 원-핫 인코딩\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "y_one_hot = tf.keras.utils.to_categorical(y_encoded, num_classes=num_classes)\n",
    "\n",
    "# 데이터 분할: 훈련 세트와 테스트 세트\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WaveNet model\n",
    "class WaveNetClassifier():\n",
    "    def __init__(self, input_shape, output_shape, kernel_size=2, dilation_depth=9, n_filters=40, task='classification', regression_range=None, load=False, load_dir='./'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "          input_shape: (tuple) tuple of input shape. (e.g. If input is 6s raw waveform with sampling rate = 16kHz, (96000,) is the input_shape)\n",
    "          output_shape: (tuple)tuple of output shape. (e.g. If we want classify the signal into 100 classes, (100,) is the output_shape)\n",
    "          kernel_size: (integer) kernel size of convolution operations in residual blocks\n",
    "          dilation_depth: (integer) type total depth of residual blocks\n",
    "          n_filters: (integer) # of filters of convolution operations in residual blocks\n",
    "          task: (string) 'classification' or 'regression'\n",
    "          regression_range: (list or tuple) target range of regression task\n",
    "          load: (bool) load previous WaveNetClassifier or not\n",
    "          load_dir: (string) the directory where the previous model exists\n",
    "        \"\"\"\n",
    "        # save task info\n",
    "        if task == 'regression':\n",
    "            if regression_range[0] == 0:\n",
    "                self.activation = 'sigmoid'\n",
    "                self.scale_ratio = regression_range[1]\n",
    "            elif regression_range[0] == - regression_range[1]:\n",
    "                self.activation = 'tanh'\n",
    "                self.scale_ratio = regression_range[1]\n",
    "            elif regression_range == None:\n",
    "                self.activation = 'linear'\n",
    "                self.scale_ratio = 1\n",
    "            else:\n",
    "                print('ERROR: wrong regression range')\n",
    "                sys.exit()\n",
    "        elif task == 'classification':\n",
    "            self.activation = 'softmax'\n",
    "            self.scale_ratio = 1\n",
    "        else:\n",
    "            print('ERROR: wrong task')\n",
    "            sys.exit()\n",
    "\n",
    "        # save input info\n",
    "        if len(input_shape) == 1:\n",
    "            self.expand_dims = True\n",
    "        elif len(input_shape) == 2:\n",
    "            self.expand_dims = False\n",
    "        else:\n",
    "            print('ERROR: wrong input shape')\n",
    "            sys.exit()\n",
    "        self.input_shape = input_shape\n",
    "\n",
    "        # save output info\n",
    "        if len(output_shape) == 1:\n",
    "            self.time_distributed = False\n",
    "        elif len(output_shape) == 2:\n",
    "            self.time_distributed = True\n",
    "        else:\n",
    "            print('ERROR: wrong output shape')\n",
    "            sys.exit()\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "        # save hyperparameters of WaveNet\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation_depth = dilation_depth\n",
    "        self.n_filters = n_filters\n",
    "        self.manual_loss = None\n",
    "\n",
    "        if load is True:\n",
    "            self.model = load_model(\n",
    "                load_dir+\"saved_wavenet_clasifier.h5\", custom_objects={'tf': tf})\n",
    "            self.prev_history = pd.read_csv(\n",
    "                load_dir+'wavenet_classifier_training_history.csv')\n",
    "            self.start_idx = len(self.prev_history)\n",
    "            self.history = None\n",
    "        else:\n",
    "            self.model = self.construct_model()\n",
    "            self.start_idx = 0\n",
    "            self.history = None\n",
    "            self.prev_history = None\n",
    "\n",
    "    def residual_block(self, x, i):\n",
    "        tanh_out = Conv1D(self.n_filters,\n",
    "                          self.kernel_size,\n",
    "                          dilation_rate=self.kernel_size**i,\n",
    "                          padding='causal',\n",
    "                          name='dilated_conv_%d_tanh' % (\n",
    "                              self.kernel_size ** i),\n",
    "                          activation='tanh'\n",
    "                          )(x)\n",
    "        sigm_out = Conv1D(self.n_filters,\n",
    "                          self.kernel_size,\n",
    "                          dilation_rate=self.kernel_size**i,\n",
    "                          padding='causal',\n",
    "                          name='dilated_conv_%d_sigm' % (\n",
    "                              self.kernel_size ** i),\n",
    "                          activation='sigmoid'\n",
    "                          )(x)\n",
    "        z = Multiply(name='gated_activation_%d' % (i))([tanh_out, sigm_out])\n",
    "        skip = Conv1D(self.n_filters, 1, name='skip_%d' % (i))(z)\n",
    "        res = Add(name='residual_block_%d' % (i))([skip, x])\n",
    "        return res, skip\n",
    "\n",
    "    def construct_model(self):\n",
    "        x = Input(shape=self.input_shape, name='original_input')\n",
    "        if self.expand_dims == True:\n",
    "            x_reshaped = Reshape(self.input_shape + (1,),\n",
    "                                 name='reshaped_input')(x)\n",
    "        else:\n",
    "            x_reshaped = x\n",
    "        skip_connections = []\n",
    "        out = Conv1D(self.n_filters, 2, dilation_rate=1,\n",
    "                     padding='causal', name='dilated_conv_1')(x_reshaped)\n",
    "        for i in range(1, self.dilation_depth + 1):\n",
    "            out, skip = self.residual_block(out, i)\n",
    "            skip_connections.append(skip)\n",
    "        out = Add(name='skip_connections')(skip_connections)\n",
    "        out = Activation('relu')(out)\n",
    "        out = Conv1D(self.n_filters, 80, strides=1, padding='same',\n",
    "                     name='conv_5ms', activation='relu')(out)\n",
    "        out = AveragePooling1D(\n",
    "            80, padding='same', name='downsample_to_200Hz')(out)\n",
    "        if self.time_distributed:\n",
    "            # prev_len / x = target_len => x = prev_len / target_len\n",
    "            target_kernel_size = (int)(\n",
    "                self.input_shape[0] / 80 / self.output_shape[0])\n",
    "            out = Conv1D(self.n_filters, target_kernel_size, padding='same',\n",
    "                         name='conv_fit_to_target', activation='relu')(out)\n",
    "            out = Conv1D(\n",
    "                self.output_shape[1], target_kernel_size, padding='same', name='conv_final')(out)\n",
    "            out = AveragePooling1D(target_kernel_size, padding='same')(out)\n",
    "            out = TimeDistributed(Activation(self.activation))(out)\n",
    "        else:\n",
    "            out = Conv1D(self.n_filters, 100, padding='same',\n",
    "                         activation='relu', name='conv_500ms')(out)\n",
    "            out = Conv1D(self.output_shape[0], 100, padding='same',\n",
    "                         activation='relu', name='conv_500ms_target_shape')(out)\n",
    "            out = AveragePooling1D(100, padding='same',\n",
    "                                   name='downsample_to_2Hz')(out)\n",
    "            out = Conv1D(self.output_shape[0], (int)(\n",
    "                self.input_shape[0] / 8000), padding='same', name='final_conv')(out)\n",
    "            out = AveragePooling1D(\n",
    "                (int)(self.input_shape[0] / 8000), name='final_pooling')(out)\n",
    "            out = Reshape(self.output_shape)(out)\n",
    "            out = Activation(self.activation)(out)\n",
    "        if self.scale_ratio != 1:\n",
    "            out = Lambda(lambda x: x * self.scale_ratio,\n",
    "                         name='output_reshaped')(out)\n",
    "        model = Model(x, out)\n",
    "        model.summary()\n",
    "        return model\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def add_loss(self, loss):\n",
    "        self.manual_loss = loss\n",
    "\n",
    "    def fit(self, X, Y, validation_data=None, epochs=100, batch_size=32, optimizer='adam', save=False, save_dir='./'):\n",
    "        # set default losses if not defined\n",
    "        if self.manual_loss is not None:\n",
    "            loss = self.manual_loss\n",
    "            metrics = None\n",
    "        else:\n",
    "            if self.task == 'classification':\n",
    "                loss = 'categorical_crossentropy'\n",
    "                metrics = ['accuracy']\n",
    "            else:\n",
    "                loss = 'mean_squared_error'\n",
    "                metrics = None\n",
    "\n",
    "        # set callback functions\n",
    "        if save:\n",
    "            saved = save_dir + \"saved_wavenet_clasifier.h5\"\n",
    "            hist = save_dir + 'wavenet_classifier_training_history.csv'\n",
    "            if validation_data is None:\n",
    "                checkpointer = ModelCheckpoint(\n",
    "                    filepath=saved, monitor='loss', verbose=1, save_best_only=True)\n",
    "            else:\n",
    "                checkpointer = ModelCheckpoint(\n",
    "                    filepath=saved, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "            history = History()\n",
    "            callbacks = [history, checkpointer]\n",
    "        else:\n",
    "            callbacks = None\n",
    "\n",
    "        # compile the model\n",
    "        self.model.compile(optimizer, loss, metrics)\n",
    "        try:\n",
    "            self.history = self.model.fit(X, Y, shuffle=True, batch_size=batch_size, epochs=epochs,\n",
    "                                          validation_data=validation_data, callbacks=callbacks, initial_epoch=self.start_idx)\n",
    "        except:\n",
    "            if save:\n",
    "                df = pd.DataFrame.from_dict(history.history)\n",
    "                df.to_csv(hist, encoding='utf-8', index=False)\n",
    "            raise Exception('fit Error')\n",
    "            sys.exit()\n",
    "        return self.history\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 13:35:21.055236: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-02 13:35:21.055642: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " original_input (InputLayer)    [(None, 80000)]      0           []                               \n",
      "                                                                                                  \n",
      " reshaped_input (Reshape)       (None, 80000, 1)     0           ['original_input[0][0]']         \n",
      "                                                                                                  \n",
      " dilated_conv_1 (Conv1D)        (None, 80000, 40)    120         ['reshaped_input[0][0]']         \n",
      "                                                                                                  \n",
      " dilated_conv_2_tanh (Conv1D)   (None, 80000, 40)    3240        ['dilated_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " dilated_conv_2_sigm (Conv1D)   (None, 80000, 40)    3240        ['dilated_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " gated_activation_1 (Multiply)  (None, 80000, 40)    0           ['dilated_conv_2_tanh[0][0]',    \n",
      "                                                                  'dilated_conv_2_sigm[0][0]']    \n",
      "                                                                                                  \n",
      " skip_1 (Conv1D)                (None, 80000, 40)    1640        ['gated_activation_1[0][0]']     \n",
      "                                                                                                  \n",
      " residual_block_1 (Add)         (None, 80000, 40)    0           ['skip_1[0][0]',                 \n",
      "                                                                  'dilated_conv_1[0][0]']         \n",
      "                                                                                                  \n",
      " dilated_conv_4_tanh (Conv1D)   (None, 80000, 40)    3240        ['residual_block_1[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_4_sigm (Conv1D)   (None, 80000, 40)    3240        ['residual_block_1[0][0]']       \n",
      "                                                                                                  \n",
      " gated_activation_2 (Multiply)  (None, 80000, 40)    0           ['dilated_conv_4_tanh[0][0]',    \n",
      "                                                                  'dilated_conv_4_sigm[0][0]']    \n",
      "                                                                                                  \n",
      " skip_2 (Conv1D)                (None, 80000, 40)    1640        ['gated_activation_2[0][0]']     \n",
      "                                                                                                  \n",
      " residual_block_2 (Add)         (None, 80000, 40)    0           ['skip_2[0][0]',                 \n",
      "                                                                  'residual_block_1[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_8_tanh (Conv1D)   (None, 80000, 40)    3240        ['residual_block_2[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_8_sigm (Conv1D)   (None, 80000, 40)    3240        ['residual_block_2[0][0]']       \n",
      "                                                                                                  \n",
      " gated_activation_3 (Multiply)  (None, 80000, 40)    0           ['dilated_conv_8_tanh[0][0]',    \n",
      "                                                                  'dilated_conv_8_sigm[0][0]']    \n",
      "                                                                                                  \n",
      " skip_3 (Conv1D)                (None, 80000, 40)    1640        ['gated_activation_3[0][0]']     \n",
      "                                                                                                  \n",
      " residual_block_3 (Add)         (None, 80000, 40)    0           ['skip_3[0][0]',                 \n",
      "                                                                  'residual_block_2[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_16_tanh (Conv1D)  (None, 80000, 40)    3240        ['residual_block_3[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_16_sigm (Conv1D)  (None, 80000, 40)    3240        ['residual_block_3[0][0]']       \n",
      "                                                                                                  \n",
      " gated_activation_4 (Multiply)  (None, 80000, 40)    0           ['dilated_conv_16_tanh[0][0]',   \n",
      "                                                                  'dilated_conv_16_sigm[0][0]']   \n",
      "                                                                                                  \n",
      " skip_4 (Conv1D)                (None, 80000, 40)    1640        ['gated_activation_4[0][0]']     \n",
      "                                                                                                  \n",
      " residual_block_4 (Add)         (None, 80000, 40)    0           ['skip_4[0][0]',                 \n",
      "                                                                  'residual_block_3[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_32_tanh (Conv1D)  (None, 80000, 40)    3240        ['residual_block_4[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_32_sigm (Conv1D)  (None, 80000, 40)    3240        ['residual_block_4[0][0]']       \n",
      "                                                                                                  \n",
      " gated_activation_5 (Multiply)  (None, 80000, 40)    0           ['dilated_conv_32_tanh[0][0]',   \n",
      "                                                                  'dilated_conv_32_sigm[0][0]']   \n",
      "                                                                                                  \n",
      " skip_5 (Conv1D)                (None, 80000, 40)    1640        ['gated_activation_5[0][0]']     \n",
      "                                                                                                  \n",
      " residual_block_5 (Add)         (None, 80000, 40)    0           ['skip_5[0][0]',                 \n",
      "                                                                  'residual_block_4[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_64_tanh (Conv1D)  (None, 80000, 40)    3240        ['residual_block_5[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_64_sigm (Conv1D)  (None, 80000, 40)    3240        ['residual_block_5[0][0]']       \n",
      "                                                                                                  \n",
      " gated_activation_6 (Multiply)  (None, 80000, 40)    0           ['dilated_conv_64_tanh[0][0]',   \n",
      "                                                                  'dilated_conv_64_sigm[0][0]']   \n",
      "                                                                                                  \n",
      " skip_6 (Conv1D)                (None, 80000, 40)    1640        ['gated_activation_6[0][0]']     \n",
      "                                                                                                  \n",
      " residual_block_6 (Add)         (None, 80000, 40)    0           ['skip_6[0][0]',                 \n",
      "                                                                  'residual_block_5[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_128_tanh (Conv1D)  (None, 80000, 40)   3240        ['residual_block_6[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_128_sigm (Conv1D)  (None, 80000, 40)   3240        ['residual_block_6[0][0]']       \n",
      "                                                                                                  \n",
      " gated_activation_7 (Multiply)  (None, 80000, 40)    0           ['dilated_conv_128_tanh[0][0]',  \n",
      "                                                                  'dilated_conv_128_sigm[0][0]']  \n",
      "                                                                                                  \n",
      " skip_7 (Conv1D)                (None, 80000, 40)    1640        ['gated_activation_7[0][0]']     \n",
      "                                                                                                  \n",
      " residual_block_7 (Add)         (None, 80000, 40)    0           ['skip_7[0][0]',                 \n",
      "                                                                  'residual_block_6[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_256_tanh (Conv1D)  (None, 80000, 40)   3240        ['residual_block_7[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_256_sigm (Conv1D)  (None, 80000, 40)   3240        ['residual_block_7[0][0]']       \n",
      "                                                                                                  \n",
      " gated_activation_8 (Multiply)  (None, 80000, 40)    0           ['dilated_conv_256_tanh[0][0]',  \n",
      "                                                                  'dilated_conv_256_sigm[0][0]']  \n",
      "                                                                                                  \n",
      " skip_8 (Conv1D)                (None, 80000, 40)    1640        ['gated_activation_8[0][0]']     \n",
      "                                                                                                  \n",
      " residual_block_8 (Add)         (None, 80000, 40)    0           ['skip_8[0][0]',                 \n",
      "                                                                  'residual_block_7[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_512_tanh (Conv1D)  (None, 80000, 40)   3240        ['residual_block_8[0][0]']       \n",
      "                                                                                                  \n",
      " dilated_conv_512_sigm (Conv1D)  (None, 80000, 40)   3240        ['residual_block_8[0][0]']       \n",
      "                                                                                                  \n",
      " gated_activation_9 (Multiply)  (None, 80000, 40)    0           ['dilated_conv_512_tanh[0][0]',  \n",
      "                                                                  'dilated_conv_512_sigm[0][0]']  \n",
      "                                                                                                  \n",
      " skip_9 (Conv1D)                (None, 80000, 40)    1640        ['gated_activation_9[0][0]']     \n",
      "                                                                                                  \n",
      " skip_connections (Add)         (None, 80000, 40)    0           ['skip_1[0][0]',                 \n",
      "                                                                  'skip_2[0][0]',                 \n",
      "                                                                  'skip_3[0][0]',                 \n",
      "                                                                  'skip_4[0][0]',                 \n",
      "                                                                  'skip_5[0][0]',                 \n",
      "                                                                  'skip_6[0][0]',                 \n",
      "                                                                  'skip_7[0][0]',                 \n",
      "                                                                  'skip_8[0][0]',                 \n",
      "                                                                  'skip_9[0][0]']                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 80000, 40)    0           ['skip_connections[0][0]']       \n",
      "                                                                                                  \n",
      " conv_5ms (Conv1D)              (None, 80000, 40)    128040      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " downsample_to_200Hz (AveragePo  (None, 1000, 40)    0           ['conv_5ms[0][0]']               \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " conv_500ms (Conv1D)            (None, 1000, 40)     160040      ['downsample_to_200Hz[0][0]']    \n",
      "                                                                                                  \n",
      " conv_500ms_target_shape (Conv1  (None, 1000, 7)     28007       ['conv_500ms[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " downsample_to_2Hz (AveragePool  (None, 10, 7)       0           ['conv_500ms_target_shape[0][0]']\n",
      " ing1D)                                                                                           \n",
      "                                                                                                  \n",
      " final_conv (Conv1D)            (None, 10, 7)        497         ['downsample_to_2Hz[0][0]']      \n",
      "                                                                                                  \n",
      " final_pooling (AveragePooling1  (None, 1, 7)        0           ['final_conv[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 7)            0           ['final_pooling[0][0]']          \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 7)            0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 389,784\n",
      "Trainable params: 389,784\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = WaveNetClassifier(\n",
    "    input_shape = (16000*5,),\n",
    "    output_shape = (7,),\n",
    "    kernel_size=2,\n",
    "    dilation_depth=9,\n",
    "    n_filters=40,\n",
    "    task='classification',\n",
    "    regression_range=None,\n",
    "    load=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
