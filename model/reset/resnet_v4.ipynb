{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ad9cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/85\n",
      "160/160 [==============================] - 612s 4s/step - loss: 1.7113 - accuracy: 0.3119 - val_loss: 1.5468 - val_accuracy: 0.3781\n",
      "Epoch 2/85\n",
      "160/160 [==============================] - 654s 4s/step - loss: 1.5503 - accuracy: 0.3977 - val_loss: 1.5416 - val_accuracy: 0.4313\n",
      "Epoch 3/85\n",
      "160/160 [==============================] - 665s 4s/step - loss: 1.4639 - accuracy: 0.4398 - val_loss: 1.4667 - val_accuracy: 0.4538\n",
      "Epoch 4/85\n",
      "160/160 [==============================] - 659s 4s/step - loss: 1.4246 - accuracy: 0.4607 - val_loss: 1.4024 - val_accuracy: 0.4456\n",
      "Epoch 5/85\n",
      "160/160 [==============================] - 657s 4s/step - loss: 1.3883 - accuracy: 0.4699 - val_loss: 1.3378 - val_accuracy: 0.5019\n",
      "Epoch 6/85\n",
      "160/160 [==============================] - 659s 4s/step - loss: 1.3499 - accuracy: 0.4982 - val_loss: 1.3587 - val_accuracy: 0.4781\n",
      "Epoch 7/85\n",
      "160/160 [==============================] - 656s 4s/step - loss: 1.3141 - accuracy: 0.5076 - val_loss: 1.2896 - val_accuracy: 0.5156\n",
      "Epoch 8/85\n",
      "160/160 [==============================] - 657s 4s/step - loss: 1.3130 - accuracy: 0.5076 - val_loss: 1.2313 - val_accuracy: 0.5531\n",
      "Epoch 9/85\n",
      "160/160 [==============================] - 661s 4s/step - loss: 1.2649 - accuracy: 0.5348 - val_loss: 1.2117 - val_accuracy: 0.5500\n",
      "Epoch 10/85\n",
      "160/160 [==============================] - 656s 4s/step - loss: 1.2311 - accuracy: 0.5430 - val_loss: 1.2369 - val_accuracy: 0.5281\n",
      "Epoch 11/85\n",
      "160/160 [==============================] - 661s 4s/step - loss: 1.2200 - accuracy: 0.5451 - val_loss: 1.1956 - val_accuracy: 0.5425\n",
      "Epoch 12/85\n",
      "160/160 [==============================] - 665s 4s/step - loss: 1.1820 - accuracy: 0.5648 - val_loss: 1.1741 - val_accuracy: 0.5675\n",
      "Epoch 13/85\n",
      "160/160 [==============================] - 663s 4s/step - loss: 1.1557 - accuracy: 0.5820 - val_loss: 1.1945 - val_accuracy: 0.5537\n",
      "Epoch 14/85\n",
      "160/160 [==============================] - 653s 4s/step - loss: 1.1562 - accuracy: 0.5725 - val_loss: 1.1380 - val_accuracy: 0.5900\n",
      "Epoch 15/85\n",
      "160/160 [==============================] - 658s 4s/step - loss: 1.0965 - accuracy: 0.6080 - val_loss: 1.1291 - val_accuracy: 0.5869\n",
      "Epoch 16/85\n",
      "160/160 [==============================] - 660s 4s/step - loss: 1.1155 - accuracy: 0.5965 - val_loss: 1.2001 - val_accuracy: 0.5750\n",
      "Epoch 17/85\n",
      "160/160 [==============================] - 661s 4s/step - loss: 1.0868 - accuracy: 0.6059 - val_loss: 1.1041 - val_accuracy: 0.6125\n",
      "Epoch 18/85\n",
      "160/160 [==============================] - 656s 4s/step - loss: 1.0698 - accuracy: 0.6121 - val_loss: 1.0570 - val_accuracy: 0.6225\n",
      "Epoch 19/85\n",
      "160/160 [==============================] - 657s 4s/step - loss: 1.0645 - accuracy: 0.6240 - val_loss: 1.0291 - val_accuracy: 0.6275\n",
      "Epoch 20/85\n",
      "160/160 [==============================] - 667s 4s/step - loss: 1.0524 - accuracy: 0.6262 - val_loss: 0.9974 - val_accuracy: 0.6531\n",
      "Epoch 21/85\n",
      "160/160 [==============================] - 665s 4s/step - loss: 1.0116 - accuracy: 0.6469 - val_loss: 0.9750 - val_accuracy: 0.6706\n",
      "Epoch 22/85\n",
      "160/160 [==============================] - 659s 4s/step - loss: 1.0075 - accuracy: 0.6473 - val_loss: 1.0251 - val_accuracy: 0.6281\n",
      "Epoch 23/85\n",
      "160/160 [==============================] - 658s 4s/step - loss: 1.0086 - accuracy: 0.6480 - val_loss: 1.0146 - val_accuracy: 0.6363\n",
      "Epoch 24/85\n",
      "160/160 [==============================] - 662s 4s/step - loss: 0.9731 - accuracy: 0.6572 - val_loss: 0.9703 - val_accuracy: 0.6600\n",
      "Epoch 25/85\n",
      "160/160 [==============================] - 661s 4s/step - loss: 0.9675 - accuracy: 0.6713 - val_loss: 0.9409 - val_accuracy: 0.6756\n",
      "Epoch 26/85\n",
      "160/160 [==============================] - 656s 4s/step - loss: 0.9329 - accuracy: 0.6787 - val_loss: 0.9790 - val_accuracy: 0.6556\n",
      "Epoch 27/85\n",
      "160/160 [==============================] - 662s 4s/step - loss: 0.9153 - accuracy: 0.6863 - val_loss: 0.8731 - val_accuracy: 0.7144\n",
      "Epoch 28/85\n",
      "160/160 [==============================] - 668s 4s/step - loss: 0.9066 - accuracy: 0.6893 - val_loss: 0.8787 - val_accuracy: 0.6925\n",
      "Epoch 29/85\n",
      "160/160 [==============================] - 660s 4s/step - loss: 0.8845 - accuracy: 0.7027 - val_loss: 0.8705 - val_accuracy: 0.6938\n",
      "Epoch 30/85\n",
      "160/160 [==============================] - 663s 4s/step - loss: 0.8854 - accuracy: 0.7014 - val_loss: 0.8420 - val_accuracy: 0.7337\n",
      "Epoch 31/85\n",
      "160/160 [==============================] - 670s 4s/step - loss: 0.8657 - accuracy: 0.7084 - val_loss: 0.8667 - val_accuracy: 0.7094\n",
      "Epoch 32/85\n",
      "160/160 [==============================] - 670s 4s/step - loss: 0.8485 - accuracy: 0.7145 - val_loss: 0.8474 - val_accuracy: 0.7337\n",
      "Epoch 33/85\n",
      "160/160 [==============================] - 672s 4s/step - loss: 0.8578 - accuracy: 0.7100 - val_loss: 0.8167 - val_accuracy: 0.7350\n",
      "Epoch 34/85\n",
      "160/160 [==============================] - 674s 4s/step - loss: 0.8161 - accuracy: 0.7338 - val_loss: 0.8529 - val_accuracy: 0.7212\n",
      "Epoch 35/85\n",
      "160/160 [==============================] - 673s 4s/step - loss: 0.7997 - accuracy: 0.7354 - val_loss: 0.7933 - val_accuracy: 0.7500\n",
      "Epoch 36/85\n",
      "160/160 [==============================] - 676s 4s/step - loss: 0.7936 - accuracy: 0.7344 - val_loss: 0.8268 - val_accuracy: 0.7181\n",
      "Epoch 37/85\n",
      "160/160 [==============================] - 675s 4s/step - loss: 0.7918 - accuracy: 0.7451 - val_loss: 0.8220 - val_accuracy: 0.6994\n",
      "Epoch 38/85\n",
      "160/160 [==============================] - 674s 4s/step - loss: 0.7799 - accuracy: 0.7512 - val_loss: 0.7517 - val_accuracy: 0.7644\n",
      "Epoch 39/85\n",
      "160/160 [==============================] - 677s 4s/step - loss: 0.7532 - accuracy: 0.7631 - val_loss: 0.7692 - val_accuracy: 0.7362\n",
      "Epoch 40/85\n",
      "160/160 [==============================] - 688s 4s/step - loss: 0.7386 - accuracy: 0.7688 - val_loss: 0.7728 - val_accuracy: 0.7444\n",
      "Epoch 41/85\n",
      "160/160 [==============================] - 707s 4s/step - loss: 0.7392 - accuracy: 0.7617 - val_loss: 0.7289 - val_accuracy: 0.7862\n",
      "Epoch 42/85\n",
      "160/160 [==============================] - 713s 4s/step - loss: 0.7347 - accuracy: 0.7666 - val_loss: 0.6615 - val_accuracy: 0.8181\n",
      "Epoch 43/85\n",
      "160/160 [==============================] - 710s 4s/step - loss: 0.7188 - accuracy: 0.7719 - val_loss: 0.7006 - val_accuracy: 0.7725\n",
      "Epoch 44/85\n",
      "160/160 [==============================] - 714s 4s/step - loss: 0.6977 - accuracy: 0.7852 - val_loss: 0.6387 - val_accuracy: 0.8163\n",
      "Epoch 45/85\n",
      "160/160 [==============================] - 720s 5s/step - loss: 0.6710 - accuracy: 0.7959 - val_loss: 0.6796 - val_accuracy: 0.7969\n",
      "Epoch 46/85\n",
      "160/160 [==============================] - 724s 5s/step - loss: 0.6747 - accuracy: 0.7865 - val_loss: 0.6859 - val_accuracy: 0.7862\n",
      "Epoch 47/85\n",
      "160/160 [==============================] - 718s 4s/step - loss: 0.6487 - accuracy: 0.8055 - val_loss: 0.6716 - val_accuracy: 0.7706\n",
      "Epoch 48/85\n",
      "160/160 [==============================] - 717s 4s/step - loss: 0.6626 - accuracy: 0.7951 - val_loss: 0.6475 - val_accuracy: 0.8125\n",
      "Epoch 49/85\n",
      "160/160 [==============================] - 725s 5s/step - loss: 0.6353 - accuracy: 0.8035 - val_loss: 0.6219 - val_accuracy: 0.8156\n",
      "Epoch 50/85\n",
      "160/160 [==============================] - 724s 5s/step - loss: 0.6346 - accuracy: 0.8037 - val_loss: 0.5825 - val_accuracy: 0.8350\n",
      "Epoch 51/85\n",
      "160/160 [==============================] - 727s 5s/step - loss: 0.6053 - accuracy: 0.8305 - val_loss: 0.5675 - val_accuracy: 0.8363\n",
      "Epoch 52/85\n",
      "160/160 [==============================] - 731s 5s/step - loss: 0.5957 - accuracy: 0.8250 - val_loss: 0.6078 - val_accuracy: 0.8175\n",
      "Epoch 53/85\n",
      "160/160 [==============================] - 728s 5s/step - loss: 0.5929 - accuracy: 0.8299 - val_loss: 0.5856 - val_accuracy: 0.8306\n",
      "Epoch 54/85\n",
      "160/160 [==============================] - 736s 5s/step - loss: 0.5933 - accuracy: 0.8205 - val_loss: 0.5715 - val_accuracy: 0.8494\n",
      "Epoch 55/85\n",
      "160/160 [==============================] - 733s 5s/step - loss: 0.5776 - accuracy: 0.8350 - val_loss: 0.5514 - val_accuracy: 0.8487\n",
      "Epoch 56/85\n",
      "160/160 [==============================] - 749s 5s/step - loss: 0.5693 - accuracy: 0.8400 - val_loss: 0.5469 - val_accuracy: 0.8550\n",
      "Epoch 57/85\n",
      "160/160 [==============================] - 801s 5s/step - loss: 0.5350 - accuracy: 0.8447 - val_loss: 0.5708 - val_accuracy: 0.8244\n",
      "Epoch 58/85\n",
      "160/160 [==============================] - 769s 5s/step - loss: 0.5365 - accuracy: 0.8482 - val_loss: 0.5747 - val_accuracy: 0.8125\n",
      "Epoch 59/85\n",
      "160/160 [==============================] - 737s 5s/step - loss: 0.5487 - accuracy: 0.8389 - val_loss: 0.5160 - val_accuracy: 0.8456\n",
      "Epoch 60/85\n",
      "160/160 [==============================] - 704s 4s/step - loss: 0.5304 - accuracy: 0.8459 - val_loss: 0.5065 - val_accuracy: 0.8494\n",
      "Epoch 61/85\n",
      "160/160 [==============================] - 773s 5s/step - loss: 0.5031 - accuracy: 0.8641 - val_loss: 0.4864 - val_accuracy: 0.8669\n",
      "Epoch 62/85\n",
      "160/160 [==============================] - 803s 5s/step - loss: 0.5015 - accuracy: 0.8652 - val_loss: 0.4788 - val_accuracy: 0.8731\n",
      "Epoch 63/85\n",
      "160/160 [==============================] - 817s 5s/step - loss: 0.4946 - accuracy: 0.8686 - val_loss: 0.4829 - val_accuracy: 0.8694\n",
      "Epoch 64/85\n",
      "160/160 [==============================] - 825s 5s/step - loss: 0.4855 - accuracy: 0.8654 - val_loss: 0.4950 - val_accuracy: 0.8606\n",
      "Epoch 65/85\n",
      "160/160 [==============================] - 817s 5s/step - loss: 0.4520 - accuracy: 0.8893 - val_loss: 0.4930 - val_accuracy: 0.8462\n",
      "Epoch 66/85\n",
      "160/160 [==============================] - 796s 5s/step - loss: 0.4550 - accuracy: 0.8813 - val_loss: 0.4405 - val_accuracy: 0.8944\n",
      "Epoch 67/85\n",
      "160/160 [==============================] - 794s 5s/step - loss: 0.4497 - accuracy: 0.8828 - val_loss: 0.4462 - val_accuracy: 0.8875\n",
      "Epoch 68/85\n",
      "160/160 [==============================] - 796s 5s/step - loss: 0.4561 - accuracy: 0.8811 - val_loss: 0.4908 - val_accuracy: 0.8369\n",
      "Epoch 69/85\n",
      "160/160 [==============================] - 949s 6s/step - loss: 0.4533 - accuracy: 0.8752 - val_loss: 0.4056 - val_accuracy: 0.9025\n",
      "Epoch 70/85\n",
      "160/160 [==============================] - 855s 5s/step - loss: 0.4315 - accuracy: 0.8930 - val_loss: 0.4082 - val_accuracy: 0.8938\n",
      "Epoch 71/85\n",
      "160/160 [==============================] - 819s 5s/step - loss: 0.4235 - accuracy: 0.8898 - val_loss: 0.4080 - val_accuracy: 0.8969\n",
      "Epoch 72/85\n",
      "160/160 [==============================] - 815s 5s/step - loss: 0.4109 - accuracy: 0.8971 - val_loss: 0.4048 - val_accuracy: 0.9100\n",
      "Epoch 73/85\n",
      "160/160 [==============================] - 889s 6s/step - loss: 0.4003 - accuracy: 0.8971 - val_loss: 0.3618 - val_accuracy: 0.9162\n",
      "Epoch 74/85\n",
      "160/160 [==============================] - 889s 6s/step - loss: 0.3973 - accuracy: 0.9029 - val_loss: 0.3658 - val_accuracy: 0.9156\n",
      "Epoch 75/85\n",
      "160/160 [==============================] - 912s 6s/step - loss: 0.3809 - accuracy: 0.9070 - val_loss: 0.3535 - val_accuracy: 0.9275\n",
      "Epoch 76/85\n",
      "160/160 [==============================] - 783s 5s/step - loss: 0.3738 - accuracy: 0.9098 - val_loss: 0.3474 - val_accuracy: 0.9281\n",
      "Epoch 77/85\n",
      "160/160 [==============================] - 947s 6s/step - loss: 0.3724 - accuracy: 0.9141 - val_loss: 0.3344 - val_accuracy: 0.9419\n",
      "Epoch 78/85\n",
      "160/160 [==============================] - 926s 6s/step - loss: 0.3589 - accuracy: 0.9170 - val_loss: 0.3628 - val_accuracy: 0.9131\n",
      "Epoch 79/85\n",
      "160/160 [==============================] - 777s 5s/step - loss: 0.3512 - accuracy: 0.9215 - val_loss: 0.3151 - val_accuracy: 0.9362\n",
      "Epoch 80/85\n",
      "160/160 [==============================] - 813s 5s/step - loss: 0.3478 - accuracy: 0.9195 - val_loss: 0.3922 - val_accuracy: 0.8963\n",
      "Epoch 81/85\n",
      "160/160 [==============================] - 900s 6s/step - loss: 0.3518 - accuracy: 0.9211 - val_loss: 0.3580 - val_accuracy: 0.9100\n",
      "Epoch 82/85\n",
      "160/160 [==============================] - 902s 6s/step - loss: 0.3265 - accuracy: 0.9268 - val_loss: 0.3162 - val_accuracy: 0.9362\n",
      "Epoch 83/85\n",
      "160/160 [==============================] - 900s 6s/step - loss: 0.3188 - accuracy: 0.9334 - val_loss: 0.3370 - val_accuracy: 0.9194\n",
      "Epoch 84/85\n",
      "160/160 [==============================] - 888s 6s/step - loss: 0.3098 - accuracy: 0.9340 - val_loss: 0.3220 - val_accuracy: 0.9144\n",
      "Epoch 85/85\n",
      "160/160 [==============================] - 897s 6s/step - loss: 0.3109 - accuracy: 0.9338 - val_loss: 0.3035 - val_accuracy: 0.9369\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet_model/assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split  # train-test split  \n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFlow GPU    \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# ResNet-50    \n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 862, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "#   \n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# ResNet-50       \n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#  \n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     \n",
    "def generate_data(data_dir, class_labels, batch_size, is_training=True):\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "        data_to_use = os.listdir(data_dir)\n",
    "        \n",
    "        if is_training:\n",
    "            data_to_use = train_test_split(data_to_use, test_size=0.2, random_state=42)[0]\n",
    "        else:\n",
    "            data_to_use = train_test_split(data_to_use, test_size=0.2, random_state=42)[1]\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            label_idx = np.random.randint(num_classes)\n",
    "            label = class_labels[label_idx]\n",
    "            class_dir = os.path.join(data_dir, label)\n",
    "            \n",
    "            #  : class_dir       .\n",
    "            filename = np.random.choice(os.listdir(class_dir))\n",
    "            file_path = os.path.join(class_dir, filename)\n",
    "\n",
    "            y, sr = librosa.load(file_path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "#    validation  \n",
    "batch_size = 32\n",
    "steps_per_epoch = 160\n",
    "epochs = 85\n",
    "\n",
    "#    \n",
    "train_data_generator = generate_data(data_dir, class_labels, batch_size, is_training=True)\n",
    "\n",
    "#    \n",
    "test_data_generator = generate_data(data_dir, class_labels, batch_size, is_training=False)\n",
    "\n",
    "#  \n",
    "history = model.fit(\n",
    "    train_data_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=test_data_generator,\n",
    "    validation_steps=50)\n",
    "\n",
    "#   \n",
    "plt.plot(history.history['accuracy'], label='training')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')  #    \n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Save the model in the recommended format\n",
    "model.save('resnet.keras')  # Save the entire model (architecture, weights, optimizer state)\n",
    "\n",
    "# If you prefer to save it using TensorFlow's SavedModel format:\n",
    "model.save('resnet_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd98e58",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'build'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#   \u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresnet.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#    \u001b[39;00m\n\u001b[1;32m      7\u001b[0m test_data_generator \u001b[38;5;241m=\u001b[39m generate_data(data_dir, class_labels, batch_size, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_api.py:230\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    231\u001b[0m         filepath,\n\u001b[1;32m    232\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    234\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    239\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    240\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:275\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    272\u001b[0m             asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:240\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 240\u001b[0m     model \u001b[38;5;241m=\u001b[39m deserialize_keras_object(\n\u001b[1;32m    241\u001b[0m         config_dict, custom_objects, safe_mode\u001b[38;5;241m=\u001b[39msafe_mode\n\u001b[1;32m    242\u001b[0m     )\n\u001b[1;32m    244\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:710\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    708\u001b[0m     compile_config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompile_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compile_config:\n\u001b[0;32m--> 710\u001b[0m         instance\u001b[38;5;241m.\u001b[39mcompile_from_config(compile_config)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[1;32m    713\u001b[0m     record_object_after_deserialization(\n\u001b[1;32m    714\u001b[0m         instance, config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshared_object_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    715\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3582\u001b[0m, in \u001b[0;36mModel.compile_from_config\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m   3579\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m   3580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m   3581\u001b[0m     \u001b[38;5;66;03m# Create optimizer variables.\u001b[39;00m\n\u001b[0;32m-> 3582\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_variables)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:997\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hyper:\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_hyper(name)\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/optimizers/legacy/optimizer_v2.py:987\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001b[39;00m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(name)\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;66;03m# Needed to avoid infinite recursion with __setattr__.\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hyper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'build'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#   \n",
    "loaded_model = load_model('resnet.keras')\n",
    "\n",
    "#    \n",
    "test_data_generator = generate_data(data_dir, class_labels, batch_size, is_training=False)\n",
    "\n",
    "#      \n",
    "test_loss, test_accuracy = loaded_model.evaluate(test_data_generator, steps=50)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "#         \n",
    "plt.plot(history.history['accuracy'], label='training')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')\n",
    "plt.plot([epochs - 1], [test_accuracy], marker='o', markersize=8, label='test', color='r')  #    \n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c64c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# .pb  \n",
    "loaded_model = tf.saved_model.load('/Users/jangminjun/Desktop/resnet_model')  # SavedModel  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffac92a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: converted_model.h5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: converted_model.h5/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# .pb  \n",
    "loaded_model = tf.saved_model.load('/Users/jangminjun/Desktop/resnet_model')\n",
    "\n",
    "# .h5  \n",
    "tf.saved_model.save(loaded_model, 'converted_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a47773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y_/kd9p7gk12s546ns_zynj91lw0000gn/T/ipykernel_41723/1552100565.py:8: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(loaded_model, 'resnet_v3.h5')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, save_model\n",
    "\n",
    "# .pb (SavedModel )  \n",
    "loaded_model = tf.keras.models.load_model('/Users/jangminjun/Desktop/resnet_model')\n",
    "\n",
    "# .h5   \n",
    "save_model(loaded_model, 'resnet_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87c88083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#  \n",
    "loaded_model = tf.keras.models.load_model('/Users/jangminjun/Desktop/resnet_v3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3654d0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 128, 862, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 134, 868, 3)          0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 64, 431, 64)          9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, 64, 431, 64)          256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, 64, 431, 64)          0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 66, 433, 64)          0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 32, 216, 64)          0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 32, 216, 64)          4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 32, 216, 64)          36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 32, 216, 256)         16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 32, 216, 256)         16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, 32, 216, 256)         1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, 32, 216, 256)         1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, 32, 216, 256)         0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, 32, 216, 256)         0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 32, 216, 64)          16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 32, 216, 64)          36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 32, 216, 256)         16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, 32, 216, 256)         1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, 32, 216, 256)         0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, 32, 216, 256)         0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 32, 216, 64)          16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 32, 216, 64)          36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 32, 216, 256)         16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, 32, 216, 256)         1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, 32, 216, 256)         0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, 32, 216, 256)         0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 16, 108, 128)         32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 16, 108, 128)         147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 16, 108, 512)         131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 16, 108, 512)         66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, 16, 108, 512)         2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, 16, 108, 512)         2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, 16, 108, 512)         0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, 16, 108, 512)         0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 16, 108, 128)         65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 16, 108, 128)         147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 16, 108, 512)         66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, 16, 108, 512)         2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, 16, 108, 512)         0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, 16, 108, 512)         0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 16, 108, 128)         65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 16, 108, 128)         147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 16, 108, 512)         66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, 16, 108, 512)         2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, 16, 108, 512)         0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, 16, 108, 512)         0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 16, 108, 128)         65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 16, 108, 128)         147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 16, 108, 512)         66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, 16, 108, 512)         2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, 16, 108, 512)         0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, 16, 108, 512)         0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 8, 54, 256)           131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 8, 54, 1024)          525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 8, 54, 256)           262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 8, 54, 256)           262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 8, 54, 256)           262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 8, 54, 256)           262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 8, 54, 256)           262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 4, 27, 512)           524800    ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 4, 27, 512)           2359808   ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 4, 27, 2048)          2099200   ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 4, 27, 2048)          1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, 4, 27, 2048)          8192      ['conv5_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNo  (None, 4, 27, 2048)          8192      ['conv5_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)      (None, 4, 27, 2048)          0         ['conv5_block1_0_bn[0][0]',   \n",
      "                                                                     'conv5_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activati  (None, 4, 27, 2048)          0         ['conv5_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 4, 27, 512)           1049088   ['conv5_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 4, 27, 512)           2359808   ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 4, 27, 2048)          1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNo  (None, 4, 27, 2048)          8192      ['conv5_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)      (None, 4, 27, 2048)          0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activati  (None, 4, 27, 2048)          0         ['conv5_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 4, 27, 512)           1049088   ['conv5_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 4, 27, 512)           2359808   ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 4, 27, 2048)          1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNo  (None, 4, 27, 2048)          8192      ['conv5_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)      (None, 4, 27, 2048)          0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activati  (None, 4, 27, 2048)          0         ['conv5_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1024)                 2098176   ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 7)                    7175      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25693063 (98.01 MB)\n",
      "Trainable params: 2105351 (8.03 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f2a4cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 87s 3s/step - loss: 0.2951 - accuracy: 0.9395\n",
      "Loss: 0.2951\n",
      "Accuracy: 93.95%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# .h5   \n",
    "model_path = '/Users/jangminjun/Desktop/resnet_v3.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "#   \n",
    "def generate_data(paths, class_labels, batch_size):\n",
    "    num_classes = len(class_labels)\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            path = np.random.choice(paths)\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "            y, sr = librosa.load(path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            label_idx = class_labels.index(label)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "\n",
    "#    train-test split \n",
    "data_paths = glob.glob(os.path.join(data_dir, \"*/*\"))\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "#   \n",
    "batch_size = 32\n",
    "\n",
    "#      \n",
    "train_data_generator = generate_data(train_paths, class_labels, batch_size)\n",
    "test_data_generator = generate_data(test_paths, class_labels, batch_size)\n",
    "\n",
    "#   \n",
    "num_test_samples = 1000  #      .      .\n",
    "steps = num_test_samples // batch_size\n",
    "\n",
    "#   \n",
    "loss, accuracy = model.evaluate(test_data_generator, steps=steps, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59333acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 85s 3s/step - loss: 0.3044 - accuracy: 0.9466\n",
      "Loss: 0.3044\n",
      "Accuracy: 94.66%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# .h5   \n",
    "model_path = '/Users/jangminjun/Desktop/resnet_v3.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "#   \n",
    "def generate_data(paths, class_labels, batch_size):\n",
    "    num_classes = len(class_labels)\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            path = np.random.choice(paths)\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "            y, sr = librosa.load(path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            label_idx = class_labels.index(label)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "\n",
    "#    train-test split \n",
    "data_paths = glob.glob(os.path.join(data_dir, \"*/*\"))\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "#   \n",
    "batch_size = 32\n",
    "\n",
    "#      \n",
    "train_data_generator = generate_data(train_paths, class_labels, batch_size)\n",
    "test_data_generator = generate_data(test_paths, class_labels, batch_size)\n",
    "\n",
    "#   \n",
    "num_test_samples = 1000  #      .      .\n",
    "steps = num_test_samples // batch_size\n",
    "\n",
    "#   \n",
    "loss, accuracy = model.evaluate(test_data_generator, steps=steps, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss:.4f}\")\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df0ab96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 86s 3s/step - loss: 0.2916 - accuracy: 0.9466\n",
      "Loss: 0.2916\n",
      "Accuracy: 0.95%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# .h5   \n",
    "model_path = '/Users/jangminjun/Desktop/resnet_v3.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "#   \n",
    "def generate_data(paths, class_labels, batch_size):\n",
    "    num_classes = len(class_labels)\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            path = np.random.choice(paths)\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "            y, sr = librosa.load(path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            label_idx = class_labels.index(label)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "\n",
    "#    train-test split \n",
    "data_paths = glob.glob(os.path.join(data_dir, \"*/*\"))\n",
    "# TensorFlow   \n",
    "tf.random.set_seed(42)\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "#   \n",
    "batch_size = 32\n",
    "\n",
    "#      \n",
    "train_data_generator = generate_data(train_paths, class_labels, batch_size)\n",
    "test_data_generator = generate_data(test_paths, class_labels, batch_size)\n",
    "\n",
    "#   \n",
    "num_test_samples = 1000  #      .      .\n",
    "steps = num_test_samples // batch_size\n",
    "\n",
    "#   \n",
    "loss, accuracy = model.evaluate(test_data_generator, steps=steps, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss:.5f}\")\n",
    "print(f\"Accuracy: {accuracy:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2804de2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 86s 3s/step - loss: 0.3067 - accuracy: 0.9395\n",
      "Loss: 0.30668\n",
      "Accuracy: 0.93952%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# .h5   \n",
    "model_path = '/Users/jangminjun/Desktop/resnet_v3.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "#   \n",
    "def generate_data(paths, class_labels, batch_size):\n",
    "    num_classes = len(class_labels)\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            path = np.random.choice(paths)\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "            y, sr = librosa.load(path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            label_idx = class_labels.index(label)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "\n",
    "#    train-test split \n",
    "data_paths = glob.glob(os.path.join(data_dir, \"*/*\"))\n",
    "# TensorFlow   \n",
    "tf.random.set_seed(42)\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "#   \n",
    "batch_size = 32\n",
    "\n",
    "#      \n",
    "train_data_generator = generate_data(train_paths, class_labels, batch_size)\n",
    "test_data_generator = generate_data(test_paths, class_labels, batch_size)\n",
    "\n",
    "#   \n",
    "num_test_samples = 1000  #      .      .\n",
    "steps = num_test_samples // batch_size\n",
    "\n",
    "#   \n",
    "loss, accuracy = model.evaluate(test_data_generator, steps=steps, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss:.5f}\")\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "652110c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 91s 3s/step - loss: 0.2893 - accuracy: 0.9375\n",
      "Loss: 0.28934\n",
      "Accuracy: 0.93750\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# .h5   \n",
    "model_path = '/Users/jangminjun/Desktop/resnet_v3.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "#   \n",
    "def generate_data(paths, class_labels, batch_size):\n",
    "    num_classes = len(class_labels)\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            path = np.random.choice(paths)\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "            y, sr = librosa.load(path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            label_idx = class_labels.index(label)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "\n",
    "#    train-test split \n",
    "data_paths = glob.glob(os.path.join(data_dir, \"*/*\"))\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "#   \n",
    "batch_size = 32\n",
    "\n",
    "#      \n",
    "train_data_generator = generate_data(train_paths, class_labels, batch_size)\n",
    "test_data_generator = generate_data(test_paths, class_labels, batch_size)\n",
    "\n",
    "#   \n",
    "num_test_samples = 1000  #      .      .\n",
    "steps = num_test_samples // batch_size\n",
    "\n",
    "#   \n",
    "loss, accuracy = model.evaluate(test_data_generator, steps=steps, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss:.5f}\")\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9efbea57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 43s 3s/step - loss: 0.2662 - accuracy: 0.9646\n",
      "Loss: 0.26615\n",
      "Accuracy: 0.96458\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# .h5   \n",
    "model_path = '/Users/jangminjun/Desktop/resnet_v3.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "#   \n",
    "def generate_data(paths, class_labels, batch_size):\n",
    "    num_classes = len(class_labels)\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            path = np.random.choice(paths)\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "            y, sr = librosa.load(path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            label_idx = class_labels.index(label)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "\n",
    "#    train-test split \n",
    "data_paths = glob.glob(os.path.join(data_dir, \"*/*\"))\n",
    "# TensorFlow   \n",
    "tf.random.set_seed(42)\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "#   \n",
    "batch_size = 32\n",
    "\n",
    "#      \n",
    "train_data_generator = generate_data(train_paths, class_labels, batch_size)\n",
    "test_data_generator = generate_data(test_paths, class_labels, batch_size)\n",
    "\n",
    "#   \n",
    "num_test_samples = 500  #      .      .\n",
    "steps = num_test_samples // batch_size\n",
    "\n",
    "#   \n",
    "loss, accuracy = model.evaluate(test_data_generator, steps=steps, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss:.5f}\")\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "902a8d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 42s 3s/step - loss: 0.2808 - accuracy: 0.9458\n",
      "Loss: 0.28077\n",
      "Accuracy: 0.94583\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "#    \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# .h5   \n",
    "model_path = '/Users/jangminjun/Desktop/resnet_v3.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "#   \n",
    "def generate_data(paths, class_labels, batch_size):\n",
    "    num_classes = len(class_labels)\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            path = np.random.choice(paths)\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "            y, sr = librosa.load(path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            label_idx = class_labels.index(label)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "\n",
    "#    train-test split \n",
    "data_paths = glob.glob(os.path.join(data_dir, \"*/*\"))\n",
    "# TensorFlow   \n",
    "tf.random.set_seed(42)\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "#   \n",
    "batch_size = 32\n",
    "\n",
    "#      \n",
    "train_data_generator = generate_data(train_paths, class_labels, batch_size)\n",
    "test_data_generator = generate_data(test_paths, class_labels, batch_size)\n",
    "\n",
    "#   \n",
    "num_test_samples = 500  #      .      .\n",
    "steps = num_test_samples // batch_size\n",
    "\n",
    "#   \n",
    "loss, accuracy = model.evaluate(test_data_generator, steps=steps, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss:.5f}\")\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7788161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 43s 3s/step - loss: 0.2808 - accuracy: 0.9458\n",
      "Loss: 0.28077\n",
      "Accuracy: 0.94583\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "#    \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# .h5   \n",
    "model_path = '/Users/jangminjun/Desktop/resnet_v3.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "#   \n",
    "def generate_data(paths, class_labels, batch_size):\n",
    "    num_classes = len(class_labels)\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            path = np.random.choice(paths)\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "            y, sr = librosa.load(path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            label_idx = class_labels.index(label)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "\n",
    "#    train-test split \n",
    "data_paths = glob.glob(os.path.join(data_dir, \"*/*\"))\n",
    "# TensorFlow   \n",
    "tf.random.set_seed(42)\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "#   \n",
    "batch_size = 32\n",
    "\n",
    "#      \n",
    "train_data_generator = generate_data(train_paths, class_labels, batch_size)\n",
    "test_data_generator = generate_data(test_paths, class_labels, batch_size)\n",
    "\n",
    "#   \n",
    "num_test_samples = 500  #      .      .\n",
    "steps = num_test_samples // batch_size\n",
    "\n",
    "#   \n",
    "loss, accuracy = model.evaluate(test_data_generator, steps=steps, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss:.5f}\")\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64e8db6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 87s 3s/step - loss: 0.2804 - accuracy: 0.9425\n",
      "Loss: 0.28042\n",
      "Accuracy: 0.94254\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "#    \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# .h5   \n",
    "model_path = '/Users/jangminjun/Desktop/resnet_v3.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "#   \n",
    "def generate_data(paths, class_labels, batch_size):\n",
    "    num_classes = len(class_labels)\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            path = np.random.choice(paths)\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "            y, sr = librosa.load(path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            label_idx = class_labels.index(label)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "\n",
    "#    train-test split \n",
    "data_paths = glob.glob(os.path.join(data_dir, \"*/*\"))\n",
    "# TensorFlow   \n",
    "tf.random.set_seed(42)\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "#   \n",
    "batch_size = 32\n",
    "\n",
    "#      \n",
    "train_data_generator = generate_data(train_paths, class_labels, batch_size)\n",
    "test_data_generator = generate_data(test_paths, class_labels, batch_size)\n",
    "\n",
    "#   \n",
    "num_test_samples = 1000\n",
    "steps = num_test_samples // batch_size\n",
    "\n",
    "#   \n",
    "loss, accuracy = model.evaluate(test_data_generator, steps=steps, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss:.5f}\")\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5ea9cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 98s 3s/step - loss: 0.3560 - accuracy: 0.9204\n",
      "Loss: 0.35596\n",
      "Accuracy: 0.92036\n"
     ]
    }
   ],
   "source": [
    "#  \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "#    \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "#    \n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# .h5   \n",
    "model_path = '/Users/jangminjun/Desktop/resnet.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "#   \n",
    "def generate_data(paths, class_labels, batch_size):\n",
    "    num_classes = len(class_labels)\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "\n",
    "        for _ in range(batch_size):\n",
    "            path = np.random.choice(paths)\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "\n",
    "            y, sr = librosa.load(path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            label_idx = class_labels.index(label)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "\n",
    "#    train-test split \n",
    "data_paths = glob.glob(os.path.join(data_dir, \"*/*\"))\n",
    "# TensorFlow   \n",
    "tf.random.set_seed(42)\n",
    "train_paths, test_paths = train_test_split(data_paths, test_size=0.2, random_state=42)\n",
    "\n",
    "#   \n",
    "batch_size = 32\n",
    "\n",
    "#      \n",
    "train_data_generator = generate_data(train_paths, class_labels, batch_size)\n",
    "test_data_generator = generate_data(test_paths, class_labels, batch_size)\n",
    "\n",
    "#   \n",
    "num_test_samples = 1000\n",
    "steps = num_test_samples // batch_size\n",
    "\n",
    "#   \n",
    "loss, accuracy = model.evaluate(test_data_generator, steps=steps, verbose=1)\n",
    "\n",
    "print(f\"Loss: {loss:.5f}\")\n",
    "print(f\"Accuracy: {accuracy:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf5e8cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 24s 3s/step - loss: 0.3007 - accuracy: 0.9464\n",
      " : [0.30069679021835327, 0.9464285969734192]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('/Users/jangminjun/Desktop/resnet_v3.h5')\n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "#    \n",
    "def generate_test_data(data_dir, class_labels, batch_size):\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            label_idx = np.random.randint(num_classes)\n",
    "            label = class_labels[label_idx]\n",
    "            class_dir = os.path.join(data_dir, label)\n",
    "            \n",
    "            # class_dir      .\n",
    "            filename = np.random.choice(os.listdir(class_dir))\n",
    "            file_path = os.path.join(class_dir, filename)\n",
    "\n",
    "            y, sr = librosa.load(file_path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "#     \n",
    "test_batch_size = 32\n",
    "test_data_generator = generate_test_data(data_dir, class_labels, test_batch_size)\n",
    "\n",
    "#  \n",
    "num_test_samples = len(class_labels) * test_batch_size  #     \n",
    "num_test_batches = int(np.ceil(num_test_samples / test_batch_size))  #    \n",
    "evaluation = loaded_model.evaluate(test_data_generator, steps=num_test_batches)\n",
    "print(\" :\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cac42d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 20s 3s/step - loss: 0.3031 - accuracy: 0.9464\n",
      " : [0.3031439483165741, 0.9464285969734192]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "\n",
    "#    \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "loaded_model = load_model('/Users/jangminjun/Desktop/resnet_v3.h5')\n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "#    \n",
    "def generate_test_data(data_dir, class_labels, batch_size):\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            label_idx = np.random.randint(num_classes)\n",
    "            label = class_labels[label_idx]\n",
    "            class_dir = os.path.join(data_dir, label)\n",
    "            \n",
    "            # class_dir      .\n",
    "            filename = np.random.choice(os.listdir(class_dir))\n",
    "            file_path = os.path.join(class_dir, filename)\n",
    "\n",
    "            y, sr = librosa.load(file_path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "#     \n",
    "test_batch_size = 32\n",
    "test_data_generator = generate_test_data(data_dir, class_labels, test_batch_size)\n",
    "\n",
    "#  \n",
    "num_test_samples = len(class_labels) * test_batch_size  #     \n",
    "num_test_batches = int(np.ceil(num_test_samples / test_batch_size))  #    \n",
    "evaluation = loaded_model.evaluate(test_data_generator, steps=num_test_batches)\n",
    "print(\" :\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b332e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 20s 3s/step - loss: 0.3668 - accuracy: 0.9062\n",
      " : [0.3667914867401123, 0.90625]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import random\n",
    "\n",
    "#    \n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "loaded_model = load_model('/Users/jangminjun/Desktop/resnet.h5')\n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "#    \n",
    "def generate_test_data(data_dir, class_labels, batch_size):\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            label_idx = np.random.randint(num_classes)\n",
    "            label = class_labels[label_idx]\n",
    "            class_dir = os.path.join(data_dir, label)\n",
    "            \n",
    "            # class_dir      .\n",
    "            filename = np.random.choice(os.listdir(class_dir))\n",
    "            file_path = os.path.join(class_dir, filename)\n",
    "\n",
    "            y, sr = librosa.load(file_path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "#     \n",
    "test_batch_size = 32\n",
    "test_data_generator = generate_test_data(data_dir, class_labels, test_batch_size)\n",
    "\n",
    "#  \n",
    "num_test_samples = len(class_labels) * test_batch_size  #     \n",
    "num_test_batches = int(np.ceil(num_test_samples / test_batch_size))  #    \n",
    "evaluation = loaded_model.evaluate(test_data_generator, steps=num_test_batches)\n",
    "print(\" :\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c598f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
