{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebfd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split  # train-test split을 위해 추가\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFlow GPU 메모리 동적 관리 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# 데이터셋 디렉토리 경로 설정\n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# ResNet-50 모델 불러오기 및 커스터마이징\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 862, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# 최종 모델 정의\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# ResNet-50 기본 모델 레이어를 고정하여 학습되지 않도록 함\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 데이터셋 및 레이블 생성 함수\n",
    "def generate_data(data_dir, class_labels, batch_size, is_training=True):\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "        data_to_use = os.listdir(data_dir)\n",
    "        \n",
    "        if is_training:\n",
    "            data_to_use = train_test_split(data_to_use, test_size=0.2, random_state=42)[0]\n",
    "        else:\n",
    "            data_to_use = train_test_split(data_to_use, test_size=0.2, random_state=42)[1]\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            label_idx = np.random.randint(num_classes)\n",
    "            label = class_labels[label_idx]\n",
    "            class_dir = os.path.join(data_dir, label)\n",
    "            \n",
    "            # 수정된 부분: class_dir 내에 있는 파일들을 이용해 무작위로 파일을 선택합니다.\n",
    "            filename = np.random.choice(os.listdir(class_dir))\n",
    "            file_path = os.path.join(class_dir, filename)\n",
    "\n",
    "            y, sr = librosa.load(file_path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "# 모델 학습 및 validation 데이터 사용(이 부분 수정)\n",
    "batch_size = 32\n",
    "steps_per_epoch = 130 \n",
    "epochs = 50\n",
    "\n",
    "# 훈련 데이터셋 생성 함수\n",
    "train_data_generator = generate_data(data_dir, class_labels, batch_size, is_training=True)\n",
    "\n",
    "# 테스트 데이터셋 생성 함수\n",
    "test_data_generator = generate_data(data_dir, class_labels, batch_size, is_training=False)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    train_data_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=test_data_generator,\n",
    "    validation_steps=50)\n",
    "\n",
    "# 학습 결과 시각화\n",
    "plt.plot(history.history['accuracy'], label='training')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')  # 검증 데이터 정확도 추가\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
