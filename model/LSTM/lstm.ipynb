{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/jaewone/developer/tensorflow/baby-cry-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constant.os import *\n",
    "from utils.os import *\n",
    "from utils.sound import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis, median_abs_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5000\n",
    "SAMPLING_FREQ = 16000\n",
    "MFCC_COEF_RETAIN = 25\n",
    "MFCC_COEF = 40\n",
    "MFCC_WINDOW_DURATION = 0.0232  # in miliseconds\n",
    "OPTIMIZER = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path):\n",
    "\n",
    "    # load wav file and normalize\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=SAMPLING_FREQ)\n",
    "    wave = librosa.util.normalize(wave)\n",
    "\n",
    "    # feature extraction\n",
    "    \"\"\"\n",
    "    ① sr\n",
    "\n",
    "    sampling rate를 말합니다. default값은 22050Hz입니다. 저희는 앞서 음성 데이터를 load 할 때 sr을 16000Hz으로 했기 때문에 꼭 sr=16000을 파라미터로 삽입해야 합니다. (사람의 목소리는 대부분 16000Hz 안에 포함된다고 합니다)\n",
    "\n",
    "    ② n_mfcc\n",
    "\n",
    "    return 될 mfcc의 개수를 정해주는 파라미터입니다. default값은 20입니다. 더 다양한 데이터 특징을 추출하기 위해서 이를 100까지 증가 시켰습니다. \n",
    "\n",
    "    ③ n_fft\n",
    "\n",
    "    frame의 length를 결정하는 파라미터 입니다. n_fft를 설정하면 window size가 자동으로 같은 값으로 설정되는데 window size의 크기로 잘린 음성이 n_fft보다 작은 경우 0으로 padding을 붙여주는 작업을 하기 때문에 n_fft는 window size보다 크거나 같아야 합니다. \n",
    "\n",
    "    일반적으로 자연어 처리에서는 음성을 25m의 크기를 기본으로 하고 있으며 16000Hz인 음성에서는 400에 해당하는 값입니다. (16000 * 0.025 = 400) 즉, n_fft는 sr에 frame_length인 0.025를 곱한 값입니다.\n",
    "\n",
    "    ④ hop_length\n",
    "\n",
    "    hop_length의 길이만큼 옆으로 가면서 데이터를 읽습니다. 10ms를 기본으로 하고 있어 16000Hz인 음성에서는 160에 해당합니다. (16000 * 0.01 = 160) 즉, hop_length는 sr에 frame_stride인 0.01를 곱해서 구할 수 있습니다.\n",
    "\n",
    "    window_length가 0.025이고 frame_stride가 0.01이라고 하면 0.015초씩은 데이터를 겹치면서 읽는다고 생각하면 됩니다.\n",
    "    \"\"\"\n",
    "    mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=MFCC_COEF, hop_length=int(\n",
    "        MFCC_WINDOW_DURATION*sr/2.0), n_fft=int(MFCC_WINDOW_DURATION*sr))\n",
    "\n",
    "    # 정규화: 평균이 0, 표준편차 1\n",
    "    mfccs = (mfccs - np.mean(mfccs))/np.std(mfccs)\n",
    "\n",
    "    # keep the first MFCC_COEF_RETAIN coefficients\n",
    "    mfccs = mfccs[:MFCC_COEF_RETAIN, :]\n",
    "\n",
    "    # calculate MFCC statistics\n",
    "    mfccs_min = mfccs.min(axis=1)\n",
    "    mfccs_max = mfccs.max(axis=1)\n",
    "    mfccs_median = np.median(mfccs, axis=1)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    mfccs_var = np.var(mfccs, axis=1)\n",
    "    mfccs_skewness = skew(mfccs, axis=1)\n",
    "    mfccs_kurtosis = kurtosis(mfccs, axis=1)\n",
    "    mfccs_mad = median_abs_deviation(mfccs, axis=1)\n",
    "\n",
    "    mfccs_first_derivative = np.diff(mfccs, n=1, axis=1)\n",
    "    mfccs_first_derivative_mean = np.mean(mfccs_first_derivative, axis=1)\n",
    "    mfccs_first_derivative_var = np.var(mfccs_first_derivative, axis=1)\n",
    "\n",
    "    mfccs_second_derivative = np.diff(mfccs, n=2, axis=1)\n",
    "    mfccs_second_derivative_mean = np.mean(mfccs_second_derivative, axis=1)\n",
    "    mfccs_second_derivative_var = np.var(mfccs_second_derivative, axis=1)\n",
    "\n",
    "    mfccs_stats = np.vstack((mfccs_min, mfccs_max, mfccs_median, mfccs_mean, mfccs_var, mfccs_skewness, mfccs_kurtosis, mfccs_mad,\n",
    "                            mfccs_first_derivative_mean, mfccs_first_derivative_var, mfccs_second_derivative_mean, mfccs_second_derivative_var))\n",
    "\n",
    "    # 첫번째 값은 mfcc의 25번째까지의 값(?) 인 것 같고 두번째 값은 특성값이다.\n",
    "    return pd.Series([mfccs, mfccs_stats.transpose()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[-3.3499403, -3.4310021, -3.427462, -2.942319...\n",
       "1    [[-7.959745, -2.8374531, -6.3970804, -5.843464...\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extrach mfcc data example\n",
    "file_path = '/Users/jaewone/developer/tensorflow/baby-cry-classification/sample_data/diaper_121.wav'\n",
    "get_mfcc(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 697/697 [00:04<00:00, 150.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>file</th>\n",
       "      <th>mfccs</th>\n",
       "      <th>mfccs_stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_134.wav</td>\n",
       "      <td>[[-4.60427, -6.3953624, -6.6822557, -6.5885105...</td>\n",
       "      <td>[[-10.103623, -1.5321517, -5.2921014, -5.49550...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_33.wav</td>\n",
       "      <td>[[-4.816056, -4.6024766, -4.8375535, -4.782134...</td>\n",
       "      <td>[[-8.788574, -2.870194, -5.5996184, -5.7096386...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_121.wav</td>\n",
       "      <td>[[-7.337755, -6.7571588, -6.6625886, -6.617184...</td>\n",
       "      <td>[[-7.337755, -2.3285367, -6.6171846, -5.985762...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state                   file  \\\n",
       "694  uncomfortable  uncomfortable_134.wav   \n",
       "695  uncomfortable   uncomfortable_33.wav   \n",
       "696  uncomfortable  uncomfortable_121.wav   \n",
       "\n",
       "                                                 mfccs  \\\n",
       "694  [[-4.60427, -6.3953624, -6.6822557, -6.5885105...   \n",
       "695  [[-4.816056, -4.6024766, -4.8375535, -4.782134...   \n",
       "696  [[-7.337755, -6.7571588, -6.6625886, -6.617184...   \n",
       "\n",
       "                                           mfccs_stats  \n",
       "694  [[-10.103623, -1.5321517, -5.2921014, -5.49550...  \n",
       "695  [[-8.788574, -2.870194, -5.5996184, -5.7096386...  \n",
       "696  [[-7.337755, -2.3285367, -6.6171846, -5.985762...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Load csv\n",
    "df = pd.read_csv(os.path.join(main_path, 'sample_data.csv'), index_col=0)[['state', 'file']]\n",
    "\n",
    "# Get MFCC data\n",
    "tqdm.pandas()\n",
    "df[['mfccs', 'mfccs_stats']] = df.progress_apply(lambda x: get_mfcc(os.path.join(main_path, 'sample_data', x['file'])), axis=1)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 697 entries, 0 to 696\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   state        697 non-null    category\n",
      " 1   file         697 non-null    object  \n",
      " 2   mfccs        697 non-null    object  \n",
      " 3   mfccs_stats  697 non-null    object  \n",
      " 4   state_code   697 non-null    int8    \n",
      "dtypes: category(1), int8(1), object(3)\n",
      "memory usage: 23.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# state 열을 카테고리 타입으로 변환한 다음 int 형태로 캐스팅한다.\n",
    "df.state = df.state.astype('category')\n",
    "df = df.assign(state_code=df.state.cat.codes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(train_df: pd.DataFrame, test_df:pd.DataFrame):\n",
    "    x_train = np.array(train_df['mfccs_stats'].to_list())\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2])\n",
    "\n",
    "    y_train = np.array(train_df['state_code'].to_list())\n",
    "    y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "\n",
    "    x_test = np.array(test_df['mfccs_stats'].to_list())\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2])\n",
    "\n",
    "    y_test = np.array(test_df['state_code'].to_list())\n",
    "    y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(num_classes):\n",
    "\n",
    "    model = tf.keras.Sequential([tf.keras.layers.LSTM(256, return_sequences=False),\n",
    "                              tf.keras.layers.BatchNormalization(),\n",
    "                              tf.keras.layers.Dropout(0.4),\n",
    "                              tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "\n",
    "    model.compile(optimizer=OPTIMIZER, loss='sparse_categorical_crossentropy', metrics=[\n",
    "                  'sparse_categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>file</th>\n",
       "      <th>mfccs</th>\n",
       "      <th>mfccs_stats</th>\n",
       "      <th>state_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>uncomfortable_121.wav</td>\n",
       "      <td>[[-7.337755, -6.7571588, -6.6625886, -6.617184...</td>\n",
       "      <td>[[-7.337755, -2.3285367, -6.6171846, -5.985762...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             state                   file  \\\n",
       "696  uncomfortable  uncomfortable_121.wav   \n",
       "\n",
       "                                                 mfccs  \\\n",
       "696  [[-7.337755, -6.7571588, -6.6625886, -6.617184...   \n",
       "\n",
       "                                           mfccs_stats  state_code  \n",
       "696  [[-7.337755, -2.3285367, -6.6171846, -5.985762...           6  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 21:13:08.284230: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-04 21:13:08.493693: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-04 21:13:08.662561: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-04 21:13:09.207329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-04 21:13:09.292712: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 11ms/step - loss: 4.3841 - sparse_categorical_accuracy: 0.5857\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_xy(train, test)\n",
    "\n",
    "lstm_model = get_lstm_model(num_classes=10)\n",
    "\n",
    "history = lstm_model.fit(X_train, Y_train, batch_size=128, epochs=EPOCHS, validation_data=(\n",
    "    X_test, Y_test), callbacks=[], verbose=0)\n",
    "\n",
    "accuracy_score = lstm_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-04 21:24:44.740804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-04 21:24:44.807854: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.47      0.42        17\n",
      "           1       0.65      0.65      0.65        26\n",
      "           2       0.44      0.48      0.46        25\n",
      "           3       0.73      0.41      0.52        27\n",
      "           4       0.73      1.00      0.84         8\n",
      "           5       0.50      0.63      0.56        19\n",
      "           6       0.88      0.78      0.82        18\n",
      "\n",
      "    accuracy                           0.59       140\n",
      "   macro avg       0.62      0.63      0.61       140\n",
      "weighted avg       0.61      0.59      0.59       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "lstm_test_preds = lstm_model.predict(X_test)\n",
    "lstm_test_pred_classes = np.argmax(lstm_test_preds, axis=1)\n",
    "\n",
    "print(classification_report(Y_test, lstm_test_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
