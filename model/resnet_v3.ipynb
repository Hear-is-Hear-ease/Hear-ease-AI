{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56d141e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/82\n",
      "152/152 [==============================] - 739s 5s/step - loss: 1.7509 - accuracy: 0.3148 - val_loss: 1.5768 - val_accuracy: 0.3925\n",
      "Epoch 2/82\n",
      "152/152 [==============================] - 738s 5s/step - loss: 1.5501 - accuracy: 0.4003 - val_loss: 1.4936 - val_accuracy: 0.4369\n",
      "Epoch 3/82\n",
      "152/152 [==============================] - 748s 5s/step - loss: 1.4522 - accuracy: 0.4428 - val_loss: 1.4515 - val_accuracy: 0.4331\n",
      "Epoch 4/82\n",
      "152/152 [==============================] - 739s 5s/step - loss: 1.4355 - accuracy: 0.4472 - val_loss: 1.3811 - val_accuracy: 0.4919\n",
      "Epoch 5/82\n",
      "152/152 [==============================] - 767s 5s/step - loss: 1.3665 - accuracy: 0.4792 - val_loss: 1.3771 - val_accuracy: 0.4706\n",
      "Epoch 6/82\n",
      "152/152 [==============================] - 796s 5s/step - loss: 1.3462 - accuracy: 0.4924 - val_loss: 1.3880 - val_accuracy: 0.4725\n",
      "Epoch 7/82\n",
      "152/152 [==============================] - 736s 5s/step - loss: 1.3046 - accuracy: 0.5134 - val_loss: 1.3372 - val_accuracy: 0.4981\n",
      "Epoch 8/82\n",
      "152/152 [==============================] - 642s 4s/step - loss: 1.3129 - accuracy: 0.5035 - val_loss: 1.3127 - val_accuracy: 0.5125\n",
      "Epoch 9/82\n",
      "152/152 [==============================] - 630s 4s/step - loss: 1.2966 - accuracy: 0.5095 - val_loss: 1.2914 - val_accuracy: 0.5281\n",
      "Epoch 10/82\n",
      "152/152 [==============================] - 629s 4s/step - loss: 1.2636 - accuracy: 0.5310 - val_loss: 1.2181 - val_accuracy: 0.5544\n",
      "Epoch 11/82\n",
      "152/152 [==============================] - 633s 4s/step - loss: 1.2362 - accuracy: 0.5428 - val_loss: 1.2114 - val_accuracy: 0.5500\n",
      "Epoch 12/82\n",
      "152/152 [==============================] - 632s 4s/step - loss: 1.2228 - accuracy: 0.5537 - val_loss: 1.1910 - val_accuracy: 0.5450\n",
      "Epoch 13/82\n",
      "152/152 [==============================] - 635s 4s/step - loss: 1.1662 - accuracy: 0.5687 - val_loss: 1.1560 - val_accuracy: 0.5750\n",
      "Epoch 14/82\n",
      "152/152 [==============================] - 646s 4s/step - loss: 1.1743 - accuracy: 0.5699 - val_loss: 1.2234 - val_accuracy: 0.5350\n",
      "Epoch 15/82\n",
      "152/152 [==============================] - 649s 4s/step - loss: 1.1623 - accuracy: 0.5746 - val_loss: 1.1633 - val_accuracy: 0.5744\n",
      "Epoch 16/82\n",
      "152/152 [==============================] - 671s 4s/step - loss: 1.1398 - accuracy: 0.5868 - val_loss: 1.1197 - val_accuracy: 0.5956\n",
      "Epoch 17/82\n",
      "152/152 [==============================] - 682s 4s/step - loss: 1.1133 - accuracy: 0.6051 - val_loss: 1.0827 - val_accuracy: 0.6181\n",
      "Epoch 18/82\n",
      "152/152 [==============================] - 683s 4s/step - loss: 1.0868 - accuracy: 0.6098 - val_loss: 1.0540 - val_accuracy: 0.6413\n",
      "Epoch 19/82\n",
      "152/152 [==============================] - 692s 5s/step - loss: 1.0793 - accuracy: 0.6108 - val_loss: 1.0675 - val_accuracy: 0.6237\n",
      "Epoch 20/82\n",
      "152/152 [==============================] - 694s 5s/step - loss: 1.0868 - accuracy: 0.6155 - val_loss: 1.0320 - val_accuracy: 0.6263\n",
      "Epoch 21/82\n",
      "152/152 [==============================] - 690s 5s/step - loss: 1.0701 - accuracy: 0.6145 - val_loss: 0.9980 - val_accuracy: 0.6319\n",
      "Epoch 22/82\n",
      "152/152 [==============================] - 690s 5s/step - loss: 1.0265 - accuracy: 0.6365 - val_loss: 0.9888 - val_accuracy: 0.6675\n",
      "Epoch 23/82\n",
      "152/152 [==============================] - 696s 5s/step - loss: 1.0332 - accuracy: 0.6295 - val_loss: 1.0872 - val_accuracy: 0.5825\n",
      "Epoch 24/82\n",
      "152/152 [==============================] - 708s 5s/step - loss: 0.9751 - accuracy: 0.6622 - val_loss: 0.9906 - val_accuracy: 0.6369\n",
      "Epoch 25/82\n",
      "152/152 [==============================] - 697s 5s/step - loss: 0.9623 - accuracy: 0.6651 - val_loss: 0.9647 - val_accuracy: 0.6656\n",
      "Epoch 26/82\n",
      "152/152 [==============================] - 700s 5s/step - loss: 0.9800 - accuracy: 0.6620 - val_loss: 0.9332 - val_accuracy: 0.6769\n",
      "Epoch 27/82\n",
      "152/152 [==============================] - 705s 5s/step - loss: 0.9734 - accuracy: 0.6651 - val_loss: 0.9317 - val_accuracy: 0.6869\n",
      "Epoch 28/82\n",
      "152/152 [==============================] - 703s 5s/step - loss: 0.9290 - accuracy: 0.6780 - val_loss: 0.9119 - val_accuracy: 0.6950\n",
      "Epoch 29/82\n",
      "152/152 [==============================] - 701s 5s/step - loss: 0.9145 - accuracy: 0.6842 - val_loss: 0.9331 - val_accuracy: 0.6944\n",
      "Epoch 30/82\n",
      "152/152 [==============================] - 702s 5s/step - loss: 0.9205 - accuracy: 0.6887 - val_loss: 0.8601 - val_accuracy: 0.7212\n",
      "Epoch 31/82\n",
      "152/152 [==============================] - 701s 5s/step - loss: 0.9080 - accuracy: 0.6972 - val_loss: 0.8783 - val_accuracy: 0.7100\n",
      "Epoch 32/82\n",
      "152/152 [==============================] - 715s 5s/step - loss: 0.9008 - accuracy: 0.6992 - val_loss: 0.9051 - val_accuracy: 0.6775\n",
      "Epoch 33/82\n",
      "152/152 [==============================] - 697s 5s/step - loss: 0.8832 - accuracy: 0.7013 - val_loss: 0.8935 - val_accuracy: 0.6800\n",
      "Epoch 34/82\n",
      "152/152 [==============================] - 663s 4s/step - loss: 0.8752 - accuracy: 0.7120 - val_loss: 0.8266 - val_accuracy: 0.7406\n",
      "Epoch 35/82\n",
      "152/152 [==============================] - 645s 4s/step - loss: 0.8467 - accuracy: 0.7235 - val_loss: 0.8437 - val_accuracy: 0.7175\n",
      "Epoch 36/82\n",
      "152/152 [==============================] - 643s 4s/step - loss: 0.8372 - accuracy: 0.7153 - val_loss: 0.8329 - val_accuracy: 0.7150\n",
      "Epoch 37/82\n",
      "152/152 [==============================] - 642s 4s/step - loss: 0.8221 - accuracy: 0.7268 - val_loss: 0.7966 - val_accuracy: 0.7456\n",
      "Epoch 38/82\n",
      "152/152 [==============================] - 644s 4s/step - loss: 0.8114 - accuracy: 0.7299 - val_loss: 0.8989 - val_accuracy: 0.6837\n",
      "Epoch 39/82\n",
      "152/152 [==============================] - 635s 4s/step - loss: 0.8187 - accuracy: 0.7305 - val_loss: 0.7969 - val_accuracy: 0.7294\n",
      "Epoch 40/82\n",
      "152/152 [==============================] - 635s 4s/step - loss: 0.8030 - accuracy: 0.7432 - val_loss: 0.7494 - val_accuracy: 0.7681\n",
      "Epoch 41/82\n",
      "152/152 [==============================] - 633s 4s/step - loss: 0.7788 - accuracy: 0.7447 - val_loss: 0.7886 - val_accuracy: 0.7319\n",
      "Epoch 42/82\n",
      "152/152 [==============================] - 637s 4s/step - loss: 0.7519 - accuracy: 0.7627 - val_loss: 0.7708 - val_accuracy: 0.7394\n",
      "Epoch 43/82\n",
      "152/152 [==============================] - 634s 4s/step - loss: 0.7421 - accuracy: 0.7654 - val_loss: 0.7409 - val_accuracy: 0.7744\n",
      "Epoch 44/82\n",
      "152/152 [==============================] - 633s 4s/step - loss: 0.7492 - accuracy: 0.7582 - val_loss: 0.7477 - val_accuracy: 0.7419\n",
      "Epoch 45/82\n",
      "152/152 [==============================] - 633s 4s/step - loss: 0.7539 - accuracy: 0.7556 - val_loss: 0.7183 - val_accuracy: 0.7725\n",
      "Epoch 46/82\n",
      "152/152 [==============================] - 650s 4s/step - loss: 0.7042 - accuracy: 0.7773 - val_loss: 0.6812 - val_accuracy: 0.7931\n",
      "Epoch 47/82\n",
      "152/152 [==============================] - 657s 4s/step - loss: 0.7095 - accuracy: 0.7669 - val_loss: 0.6815 - val_accuracy: 0.7856\n",
      "Epoch 48/82\n",
      "152/152 [==============================] - 674s 4s/step - loss: 0.6899 - accuracy: 0.7825 - val_loss: 0.6719 - val_accuracy: 0.7969\n",
      "Epoch 49/82\n",
      "152/152 [==============================] - 691s 5s/step - loss: 0.6992 - accuracy: 0.7757 - val_loss: 0.6518 - val_accuracy: 0.7981\n",
      "Epoch 50/82\n",
      "152/152 [==============================] - 686s 5s/step - loss: 0.6683 - accuracy: 0.7907 - val_loss: 0.6561 - val_accuracy: 0.8100\n",
      "Epoch 51/82\n",
      "152/152 [==============================] - 696s 5s/step - loss: 0.6620 - accuracy: 0.7850 - val_loss: 0.6752 - val_accuracy: 0.7944\n",
      "Epoch 52/82\n",
      "152/152 [==============================] - 696s 5s/step - loss: 0.6208 - accuracy: 0.8111 - val_loss: 0.6771 - val_accuracy: 0.7844\n",
      "Epoch 53/82\n",
      "152/152 [==============================] - 703s 5s/step - loss: 0.6327 - accuracy: 0.8032 - val_loss: 0.6007 - val_accuracy: 0.8375\n",
      "Epoch 54/82\n",
      "152/152 [==============================] - 702s 5s/step - loss: 0.6390 - accuracy: 0.8024 - val_loss: 0.6522 - val_accuracy: 0.7987\n",
      "Epoch 55/82\n",
      "152/152 [==============================] - 703s 5s/step - loss: 0.6220 - accuracy: 0.8127 - val_loss: 0.6150 - val_accuracy: 0.8300\n",
      "Epoch 56/82\n",
      "152/152 [==============================] - 705s 5s/step - loss: 0.6137 - accuracy: 0.8222 - val_loss: 0.5939 - val_accuracy: 0.8244\n",
      "Epoch 57/82\n",
      "152/152 [==============================] - 711s 5s/step - loss: 0.5815 - accuracy: 0.8378 - val_loss: 0.6201 - val_accuracy: 0.8231\n",
      "Epoch 58/82\n",
      "152/152 [==============================] - 719s 5s/step - loss: 0.5890 - accuracy: 0.8339 - val_loss: 0.6037 - val_accuracy: 0.8231\n",
      "Epoch 59/82\n",
      "152/152 [==============================] - 720s 5s/step - loss: 0.5898 - accuracy: 0.8314 - val_loss: 0.5583 - val_accuracy: 0.8406\n",
      "Epoch 60/82\n",
      "152/152 [==============================] - 724s 5s/step - loss: 0.5650 - accuracy: 0.8390 - val_loss: 0.5415 - val_accuracy: 0.8388\n",
      "Epoch 61/82\n",
      "152/152 [==============================] - 720s 5s/step - loss: 0.5559 - accuracy: 0.8483 - val_loss: 0.5427 - val_accuracy: 0.8400\n",
      "Epoch 62/82\n",
      "152/152 [==============================] - 717s 5s/step - loss: 0.5521 - accuracy: 0.8468 - val_loss: 0.5310 - val_accuracy: 0.8544\n",
      "Epoch 63/82\n",
      "152/152 [==============================] - 725s 5s/step - loss: 0.5110 - accuracy: 0.8623 - val_loss: 0.5050 - val_accuracy: 0.8569\n",
      "Epoch 64/82\n",
      "152/152 [==============================] - 731s 5s/step - loss: 0.5209 - accuracy: 0.8579 - val_loss: 0.5429 - val_accuracy: 0.8506\n",
      "Epoch 65/82\n",
      "152/152 [==============================] - 739s 5s/step - loss: 0.5209 - accuracy: 0.8567 - val_loss: 0.5012 - val_accuracy: 0.8519\n",
      "Epoch 66/82\n",
      "152/152 [==============================] - 743s 5s/step - loss: 0.5336 - accuracy: 0.8413 - val_loss: 0.4922 - val_accuracy: 0.8700\n",
      "Epoch 67/82\n",
      "152/152 [==============================] - 748s 5s/step - loss: 0.4989 - accuracy: 0.8637 - val_loss: 0.5000 - val_accuracy: 0.8600\n",
      "Epoch 68/82\n",
      "152/152 [==============================] - 748s 5s/step - loss: 0.4959 - accuracy: 0.8614 - val_loss: 0.4765 - val_accuracy: 0.8631\n",
      "Epoch 69/82\n",
      "152/152 [==============================] - 752s 5s/step - loss: 0.4889 - accuracy: 0.8657 - val_loss: 0.4518 - val_accuracy: 0.8813\n",
      "Epoch 70/82\n",
      "152/152 [==============================] - 752s 5s/step - loss: 0.4603 - accuracy: 0.8832 - val_loss: 0.5274 - val_accuracy: 0.8319\n",
      "Epoch 71/82\n",
      "152/152 [==============================] - 751s 5s/step - loss: 0.4953 - accuracy: 0.8625 - val_loss: 0.5312 - val_accuracy: 0.8338\n",
      "Epoch 72/82\n",
      "152/152 [==============================] - 756s 5s/step - loss: 0.4466 - accuracy: 0.8869 - val_loss: 0.4486 - val_accuracy: 0.8906\n",
      "Epoch 73/82\n",
      "152/152 [==============================] - 758s 5s/step - loss: 0.4395 - accuracy: 0.8857 - val_loss: 0.4342 - val_accuracy: 0.8856\n",
      "Epoch 74/82\n",
      "152/152 [==============================] - 767s 5s/step - loss: 0.4433 - accuracy: 0.8773 - val_loss: 0.4122 - val_accuracy: 0.8925\n",
      "Epoch 75/82\n",
      "152/152 [==============================] - 770s 5s/step - loss: 0.4615 - accuracy: 0.8791 - val_loss: 0.4290 - val_accuracy: 0.8938\n",
      "Epoch 76/82\n",
      "152/152 [==============================] - 783s 5s/step - loss: 0.4147 - accuracy: 0.8960 - val_loss: 0.3958 - val_accuracy: 0.9087\n",
      "Epoch 77/82\n",
      "152/152 [==============================] - 776s 5s/step - loss: 0.4214 - accuracy: 0.8904 - val_loss: 0.3887 - val_accuracy: 0.9119\n",
      "Epoch 78/82\n",
      "152/152 [==============================] - 810s 5s/step - loss: 0.4182 - accuracy: 0.8914 - val_loss: 0.4040 - val_accuracy: 0.9006\n",
      "Epoch 79/82\n",
      "152/152 [==============================] - 797s 5s/step - loss: 0.3902 - accuracy: 0.9116 - val_loss: 0.4084 - val_accuracy: 0.8963\n",
      "Epoch 80/82\n",
      "152/152 [==============================] - 800s 5s/step - loss: 0.3854 - accuracy: 0.9052 - val_loss: 0.3765 - val_accuracy: 0.9200\n",
      "Epoch 81/82\n",
      "152/152 [==============================] - 813s 5s/step - loss: 0.3815 - accuracy: 0.9079 - val_loss: 0.3673 - val_accuracy: 0.9181\n",
      "Epoch 82/82\n",
      "152/152 [==============================] - 811s 5s/step - loss: 0.3761 - accuracy: 0.9102 - val_loss: 0.3851 - val_accuracy: 0.8994\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jangminjun/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split  # train-test split을 위해 추가\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "\n",
    "# TensorFlow GPU 메모리 동적 관리 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# 데이터셋 디렉토리 경로 설정\n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# ResNet-50 모델 불러오기 및 커스터마이징\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(128, 862, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# 최종 모델 정의\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# ResNet-50 기본 모델 레이어를 고정하여 학습되지 않도록 함\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 데이터셋 및 레이블 생성 함수\n",
    "def generate_data(data_dir, class_labels, batch_size, is_training=True):\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "        data_to_use = os.listdir(data_dir)\n",
    "        \n",
    "        if is_training:\n",
    "            data_to_use = train_test_split(data_to_use, test_size=0.2, random_state=42)[0]\n",
    "        else:\n",
    "            data_to_use = train_test_split(data_to_use, test_size=0.2, random_state=42)[1]\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            label_idx = np.random.randint(num_classes)\n",
    "            label = class_labels[label_idx]\n",
    "            class_dir = os.path.join(data_dir, label)\n",
    "            \n",
    "            # 수정된 부분: class_dir 내에 있는 파일들을 이용해 무작위로 파일을 선택합니다.\n",
    "            filename = np.random.choice(os.listdir(class_dir))\n",
    "            file_path = os.path.join(class_dir, filename)\n",
    "\n",
    "            y, sr = librosa.load(file_path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "# 모델 학습 및 validation 데이터 사용\n",
    "batch_size = 32\n",
    "steps_per_epoch = 152\n",
    "epochs = 82\n",
    "\n",
    "# 훈련 데이터셋 생성 함수\n",
    "train_data_generator = generate_data(data_dir, class_labels, batch_size, is_training=True)\n",
    "\n",
    "# 테스트 데이터셋 생성 함수\n",
    "test_data_generator = generate_data(data_dir, class_labels, batch_size, is_training=False)\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    train_data_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=test_data_generator,\n",
    "    validation_steps=50)\n",
    "\n",
    "# 학습 결과 시각화\n",
    "plt.plot(history.history['accuracy'], label='training')\n",
    "plt.plot(history.history['val_accuracy'], label='validation')  # 검증 데이터 정확도 추가\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model.save('resnet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ca5228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model('resnet.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b05b1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 862, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 134, 868, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 64, 431, 64)          9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalizati  (None, 64, 431, 64)          256       ['conv1_conv[0][0]']          \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)     (None, 64, 431, 64)          0         ['conv1_bn[0][0]']            \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 66, 433, 64)          0         ['conv1_relu[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 32, 216, 64)          0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 32, 216, 64)          4160      ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 32, 216, 64)          36928     ['conv2_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 32, 216, 256)         16640     ['pool1_pool[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 32, 216, 256)         16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNo  (None, 32, 216, 256)         1024      ['conv2_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNo  (None, 32, 216, 256)         1024      ['conv2_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)      (None, 32, 216, 256)         0         ['conv2_block1_0_bn[0][0]',   \n",
      "                                                                     'conv2_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activati  (None, 32, 216, 256)         0         ['conv2_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 32, 216, 64)          16448     ['conv2_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 32, 216, 64)          36928     ['conv2_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 32, 216, 256)         16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNo  (None, 32, 216, 256)         1024      ['conv2_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)      (None, 32, 216, 256)         0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activati  (None, 32, 216, 256)         0         ['conv2_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 32, 216, 64)          16448     ['conv2_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 32, 216, 64)          36928     ['conv2_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 32, 216, 64)          256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 32, 216, 64)          0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 32, 216, 256)         16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNo  (None, 32, 216, 256)         1024      ['conv2_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)      (None, 32, 216, 256)         0         ['conv2_block2_out[0][0]',    \n",
      "                                                                     'conv2_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activati  (None, 32, 216, 256)         0         ['conv2_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 16, 108, 128)         32896     ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 16, 108, 128)         147584    ['conv3_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 16, 108, 512)         131584    ['conv2_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 16, 108, 512)         66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNo  (None, 16, 108, 512)         2048      ['conv3_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNo  (None, 16, 108, 512)         2048      ['conv3_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)      (None, 16, 108, 512)         0         ['conv3_block1_0_bn[0][0]',   \n",
      "                                                                     'conv3_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activati  (None, 16, 108, 512)         0         ['conv3_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 16, 108, 128)         65664     ['conv3_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 16, 108, 128)         147584    ['conv3_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 16, 108, 512)         66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNo  (None, 16, 108, 512)         2048      ['conv3_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)      (None, 16, 108, 512)         0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activati  (None, 16, 108, 512)         0         ['conv3_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 16, 108, 128)         65664     ['conv3_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 16, 108, 128)         147584    ['conv3_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 16, 108, 512)         66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNo  (None, 16, 108, 512)         2048      ['conv3_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)      (None, 16, 108, 512)         0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activati  (None, 16, 108, 512)         0         ['conv3_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 16, 108, 128)         65664     ['conv3_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 16, 108, 128)         147584    ['conv3_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 16, 108, 128)         512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 16, 108, 128)         0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 16, 108, 512)         66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNo  (None, 16, 108, 512)         2048      ['conv3_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)      (None, 16, 108, 512)         0         ['conv3_block3_out[0][0]',    \n",
      "                                                                     'conv3_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activati  (None, 16, 108, 512)         0         ['conv3_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 8, 54, 256)           131328    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 8, 54, 1024)          525312    ['conv3_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block1_0_bn[0][0]',   \n",
      "                                                                     'conv4_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 8, 54, 256)           262400    ['conv4_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 8, 54, 256)           262400    ['conv4_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 8, 54, 256)           262400    ['conv4_block3_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block4_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block4_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block4_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 8, 54, 256)           262400    ['conv4_block4_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block5_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block5_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block5_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 8, 54, 256)           262400    ['conv4_block5_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 8, 54, 256)           590080    ['conv4_block6_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 8, 54, 256)           1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 8, 54, 256)           0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 8, 54, 1024)          263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNo  (None, 8, 54, 1024)          4096      ['conv4_block6_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)      (None, 8, 54, 1024)          0         ['conv4_block5_out[0][0]',    \n",
      "                                                                     'conv4_block6_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activati  (None, 8, 54, 1024)          0         ['conv4_block6_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 4, 27, 512)           524800    ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 4, 27, 512)           2359808   ['conv5_block1_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 4, 27, 2048)          2099200   ['conv4_block6_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 4, 27, 2048)          1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNo  (None, 4, 27, 2048)          8192      ['conv5_block1_0_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNo  (None, 4, 27, 2048)          8192      ['conv5_block1_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)      (None, 4, 27, 2048)          0         ['conv5_block1_0_bn[0][0]',   \n",
      "                                                                     'conv5_block1_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activati  (None, 4, 27, 2048)          0         ['conv5_block1_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 4, 27, 512)           1049088   ['conv5_block1_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 4, 27, 512)           2359808   ['conv5_block2_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 4, 27, 2048)          1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNo  (None, 4, 27, 2048)          8192      ['conv5_block2_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)      (None, 4, 27, 2048)          0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activati  (None, 4, 27, 2048)          0         ['conv5_block2_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 4, 27, 512)           1049088   ['conv5_block2_out[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 4, 27, 512)           2359808   ['conv5_block3_1_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 4, 27, 512)           2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 4, 27, 512)           0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 4, 27, 2048)          1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNo  (None, 4, 27, 2048)          8192      ['conv5_block3_3_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)      (None, 4, 27, 2048)          0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_bn[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activati  (None, 4, 27, 2048)          0         ['conv5_block3_add[0][0]']    \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 2048)                 0         ['conv5_block3_out[0][0]']    \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 2098176   ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 7)                    7175      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25693063 (98.01 MB)\n",
      "Trainable params: 2105351 (8.03 MB)\n",
      "Non-trainable params: 23587712 (89.98 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6809ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(file_path):\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "    mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    RATIO = 862 / 64\n",
    "    mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                 anti_aliasing=True, mode='reflect')\n",
    "    mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "    return mel_spec_dB_stacked\n",
    "\n",
    "# 예측 수행 함수 정의\n",
    "def predict_audio(file_path):\n",
    "    preprocessed_input = preprocess_input(file_path)\n",
    "    preprocessed_input = np.expand_dims(preprocessed_input, axis=0)  # 배치 차원 추가\n",
    "    predictions = loaded_model.predict(preprocessed_input)\n",
    "    predicted_class_idx = np.argmax(predictions)\n",
    "    predicted_class_label = class_labels[predicted_class_idx]\n",
    "    return predicted_class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6a93a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 450ms/step\n",
      "예측된 클래스 레이블: awake\n"
     ]
    }
   ],
   "source": [
    "audio_file_path = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data/awake/awake_1.wav'  # 예측하려는 오디오 파일 경로로 바꾸세요.\n",
    "predicted_label = predict_audio(audio_file_path)\n",
    "print(\"예측된 클래스 레이블:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc26abf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 20s 3s/step - loss: 0.4273 - accuracy: 0.8750\n",
      "평가 결과: [0.42725178599357605, 0.875]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('resnet.h5')\n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# 테스트 데이터셋 생성 함수\n",
    "def generate_test_data(data_dir, class_labels, batch_size):\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            label_idx = np.random.randint(num_classes)\n",
    "            label = class_labels[label_idx]\n",
    "            class_dir = os.path.join(data_dir, label)\n",
    "            \n",
    "            # class_dir 내에 있는 파일들을 이용해 파일을 선택합니다.\n",
    "            filename = np.random.choice(os.listdir(class_dir))\n",
    "            file_path = os.path.join(class_dir, filename)\n",
    "\n",
    "            y, sr = librosa.load(file_path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "# 테스트 데이터셋 생성 함수 사용\n",
    "test_batch_size = 32\n",
    "test_data_generator = generate_test_data(data_dir, class_labels, test_batch_size)\n",
    "\n",
    "# 모델 평가\n",
    "num_test_samples = len(class_labels) * test_batch_size  # 전체 테스트 샘플 수 계산\n",
    "num_test_batches = int(np.ceil(num_test_samples / test_batch_size))  # 테스트 배치 수 계산\n",
    "evaluation = loaded_model.evaluate(test_data_generator, steps=num_test_batches)\n",
    "print(\"평가 결과:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b7ed54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 20s 3s/step - loss: 0.4060 - accuracy: 0.8973\n",
      "평가 결과: [0.4060058891773224, 0.8973214030265808]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('resnet.h5')\n",
    "data_dir = '/Users/jangminjun/Desktop/babyproject/hear_ease-infant_crying_classification/data'\n",
    "class_labels = os.listdir(data_dir)\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "# 테스트 데이터셋 생성 함수\n",
    "def generate_test_data(data_dir, class_labels, batch_size):\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_labels = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            label_idx = np.random.randint(num_classes)\n",
    "            label = class_labels[label_idx]\n",
    "            class_dir = os.path.join(data_dir, label)\n",
    "            \n",
    "            # class_dir 내에 있는 파일들을 이용해 파일을 선택합니다.\n",
    "            filename = np.random.choice(os.listdir(class_dir))\n",
    "            file_path = os.path.join(class_dir, filename)\n",
    "\n",
    "            y, sr = librosa.load(file_path, sr=16000)\n",
    "            mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, n_fft=2048, hop_length=501)\n",
    "            mel_spec_dB = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            RATIO = 862 / 64\n",
    "            mel_spec_dB_resized = resize(mel_spec_dB, (mel_spec_dB.shape[0], mel_spec_dB.shape[1] * RATIO),\n",
    "                                         anti_aliasing=True, mode='reflect')\n",
    "            mel_spec_dB_stacked = np.stack([mel_spec_dB_resized] * 3, axis=-1)\n",
    "            batch_X.append(mel_spec_dB_stacked)\n",
    "            batch_labels.append(label_idx)\n",
    "\n",
    "        batch_X = np.array(batch_X)\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=num_classes)\n",
    "        yield batch_X, batch_labels\n",
    "\n",
    "# 테스트 데이터셋 생성 함수 사용\n",
    "test_batch_size = 32\n",
    "test_data_generator = generate_test_data(data_dir, class_labels, test_batch_size)\n",
    "\n",
    "# 모델 평가\n",
    "num_test_samples = len(class_labels) * test_batch_size  # 전체 테스트 샘플 수 계산\n",
    "num_test_batches = int(np.ceil(num_test_samples / test_batch_size))  # 테스트 배치 수 계산\n",
    "evaluation = loaded_model.evaluate(test_data_generator, steps=num_test_batches)\n",
    "print(\"평가 결과:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc5c52d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
