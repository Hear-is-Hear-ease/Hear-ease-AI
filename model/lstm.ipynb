{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import sys\n",
    "\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis, median_abs_deviation\n",
    "\n",
    "sys.path.append('/Users/jaewone/developer/tensorflow/baby-cry-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constant.os import *\n",
    "from utils.os import *\n",
    "from utils.sound import *\n",
    "from trans_data.get_state_list import get_state_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path,\n",
    "             sampling_freq=16000,\n",
    "             mfcc_coef=40,\n",
    "             mfcc_coef_retain=25,\n",
    "             mfcc_window_duration=0.0232):\n",
    "    \"\"\"\n",
    "    오디오 파일에 대한 MFCC를 분석한 뒤 값을 반환한다.\n",
    "\n",
    "    Parameters:\n",
    "        file_path:            오디오 파일의 경로\n",
    "        sampling_freq:        sampling rate\n",
    "        mfcc_coef:            frame의 길이를 결정하는 파라미터.\n",
    "        mfcc_coef_retain:     유지되는 MFCC 값의 길이\n",
    "        mfcc_window_duration: 데이터를 읽을 때 겹쳐 읽는 길이(sec)\n",
    "\n",
    "    Returns:\n",
    "        list[0]: 초반 mfcc_coef_retain 만큼의 MFCC 값\n",
    "        list[1]: 평균, 분산, 표준편차와 같은 MFCC의 특성값\n",
    "    \"\"\"\n",
    "\n",
    "    # load wav file and normalize\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=sampling_freq)\n",
    "    wave = librosa.util.normalize(wave)\n",
    "\n",
    "    # feature extraction\n",
    "    \"\"\"\n",
    "    ① sr: sampling rate\n",
    "    ② n_mfcc=20 : mfcc의 개수\n",
    "    ③ n_fft=25\n",
    "        frame의 길이를 결정하는 파라미터 입니다. n_fft를 설정하면 window size가 자동으로 같은 값으로 설정되는데 window size의 크기로 잘린 음성이 n_fft보다 작은 경우 0으로 padding을 붙여주는 작업을 하기 때문에 n_fft는 window size보다 크거나 같아야 한다.\n",
    "        보통 n_fft = sr * frame_length 로 설정\n",
    "    ④ hop_length=10\n",
    "        hop_length의 길이만큼 옆으로 가면서 데이터를 읽는다. \n",
    "        10ms를 기본으로 하고 있어 16000Hz인 음성에서는 160에 해당한다. (16000 * 0.01 = 160)\n",
    "        보통 hop_length는 = sr * frame_stride 로 설정한다.\n",
    "    \"\"\"\n",
    "    mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=mfcc_coef, hop_length=int(\n",
    "        mfcc_window_duration*sr/2.0), n_fft=int(mfcc_window_duration*sr))\n",
    "\n",
    "    # 정규화: 평균이 0, 표준편차 1\n",
    "    mfccs = (mfccs - np.mean(mfccs))/np.std(mfccs)\n",
    "\n",
    "    # keep the first mfcc_coef_retain coefficients\n",
    "    \"\"\"\n",
    "    일부 계수를 폐기하는 이유는 무엇입니까? \n",
    "    일반적으로 하위 MFCC는 스펙트럼의 전체 모양에 대한 더 많은 정보를 포함하고(따라서 더 중요함) 상위 MFCC는 스펙트럼에서 더 미세한 세부 사항을 나타내기 시작합니다. \n",
    "    처음 25개의 MFCC만 유지하도록 선택함으로써 작성자는 마지막 15개의 계수(26에서 40까지)가 모델의 증가된 복잡성을 정당화할 만큼 중요한 정보를 충분히 전달하지 않는다고 결정했을 가능성이 큽니다.\n",
    "    즉, 유지할 MFCC 수의 선택은 문제에 따라 다를 수 있으며 다른 응용 프로그램이나 모델에는 다른 수가 필요할 수 있습니다. 일부 응용 프로그램의 경우 처음 13개의 계수만 사용되는 반면 \n",
    "    다른 응용 프로그램의 경우 40개 모두 사용될 수 있습니다. 주어진 작업에 대한 최적의 수를 찾으려면 종종 어느 정도의 실험이 필요합니다.\n",
    "    \"\"\"\n",
    "    mfccs = mfccs[:mfcc_coef_retain, :]\n",
    "\n",
    "    # calculate MFCC statistics\n",
    "    mfccs_min = mfccs.min(axis=1)\n",
    "    mfccs_max = mfccs.max(axis=1)\n",
    "    mfccs_median = np.median(mfccs, axis=1)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    mfccs_var = np.var(mfccs, axis=1)\n",
    "    mfccs_skewness = skew(mfccs, axis=1)\n",
    "    mfccs_kurtosis = kurtosis(mfccs, axis=1)\n",
    "    mfccs_mad = median_abs_deviation(mfccs, axis=1)\n",
    "\n",
    "    mfccs_first_derivative = np.diff(mfccs, n=1, axis=1)\n",
    "    mfccs_first_derivative_mean = np.mean(mfccs_first_derivative, axis=1)\n",
    "    mfccs_first_derivative_var = np.var(mfccs_first_derivative, axis=1)\n",
    "\n",
    "    mfccs_second_derivative = np.diff(mfccs, n=2, axis=1)\n",
    "    mfccs_second_derivative_mean = np.mean(mfccs_second_derivative, axis=1)\n",
    "    mfccs_second_derivative_var = np.var(mfccs_second_derivative, axis=1)\n",
    "\n",
    "    mfccs_stats = np.vstack((mfccs_min, mfccs_max, mfccs_median, mfccs_mean, mfccs_var, mfccs_skewness, mfccs_kurtosis, mfccs_mad,\n",
    "                            mfccs_first_derivative_mean, mfccs_first_derivative_var, mfccs_second_derivative_mean, mfccs_second_derivative_var))\n",
    "\n",
    "    return pd.Series([mfccs, mfccs_stats.transpose()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaewone/ENTER/envs/tf25/lib/python3.9/site-packages/numba/cpython/hashing.py:482: UserWarning: FNV hashing is not implemented in Numba. See PEP 456 https://www.python.org/dev/peps/pep-0456/ for rationale over not using FNV. Numba will continue to work, but hashes for built in types will be computed using siphash24. This will permit e.g. dictionaries to continue to behave as expected, however anything relying on the value of the hash opposed to hash as a derived property is likely to not work as expected.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>duration</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>uncomfortable_26.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>uncomfortable_135.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>uncomfortable_121.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  duration          state\n",
       "3777   uncomfortable_26.wav       5.0  uncomfortable\n",
       "3778  uncomfortable_135.wav       5.0  uncomfortable\n",
       "3779  uncomfortable_121.wav       5.0  uncomfortable"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = get_state_file_list(data_path)\n",
    "\n",
    "df = pd.DataFrame({'file':file_list})\n",
    "df['duration'] = df['file'].apply(lambda file: get_duration(file))\n",
    "df['file'] = df['file'].apply(lambda file: file.rsplit('/', 1)[1])\n",
    "df['state'] = df['file'].apply(lambda file: file.split('_', 1)[0]).astype('category')\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3780/3780 [00:21<00:00, 176.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>duration</th>\n",
       "      <th>state</th>\n",
       "      <th>mfccs</th>\n",
       "      <th>mfccs_stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>uncomfortable_26.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>[[-4.3504543, -5.236452, -6.342514, -7.1463065...</td>\n",
       "      <td>[[-9.110636, -2.3387036, -5.156799, -5.707635,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>uncomfortable_135.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>[[-8.662221, -8.44758, -8.300998, -8.377636, -...</td>\n",
       "      <td>[[-9.005152, -3.2621493, -5.396605, -5.693153,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>uncomfortable_121.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>[[-4.7594666, -5.517606, -5.418749, -5.6038866...</td>\n",
       "      <td>[[-9.625122, -2.6052177, -5.5111856, -5.635483...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  duration          state  \\\n",
       "3777   uncomfortable_26.wav       5.0  uncomfortable   \n",
       "3778  uncomfortable_135.wav       5.0  uncomfortable   \n",
       "3779  uncomfortable_121.wav       5.0  uncomfortable   \n",
       "\n",
       "                                                  mfccs  \\\n",
       "3777  [[-4.3504543, -5.236452, -6.342514, -7.1463065...   \n",
       "3778  [[-8.662221, -8.44758, -8.300998, -8.377636, -...   \n",
       "3779  [[-4.7594666, -5.517606, -5.418749, -5.6038866...   \n",
       "\n",
       "                                            mfccs_stats  \n",
       "3777  [[-9.110636, -2.3387036, -5.156799, -5.707635,...  \n",
       "3778  [[-9.005152, -3.2621493, -5.396605, -5.693153,...  \n",
       "3779  [[-9.625122, -2.6052177, -5.5111856, -5.635483...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get MFCC data\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "df[['mfccs', 'mfccs_stats']] = df.progress_apply(lambda x: get_mfcc(os.path.join(data_path, x['state'], x['file'])), axis=1)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3780 entries, 0 to 3779\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   file         3780 non-null   object  \n",
      " 1   duration     3780 non-null   float64 \n",
      " 2   state        3780 non-null   category\n",
      " 3   mfccs        3780 non-null   object  \n",
      " 4   mfccs_stats  3780 non-null   object  \n",
      " 5   state_code   3780 non-null   int8    \n",
      "dtypes: category(1), float64(1), int8(1), object(3)\n",
      "memory usage: 126.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# state 열을 카테고리 타입으로 변환한 다음 int 형태로 캐스팅한다.\n",
    "df.state = df.state.astype('category')\n",
    "df = df.assign(state_code=df.state.cat.codes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(train_df: pd.DataFrame, test_df:pd.DataFrame):\n",
    "    x_train = np.array(train_df['mfccs_stats'].to_list())\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2])\n",
    "\n",
    "    y_train = np.array(train_df['state_code'].to_list())\n",
    "    y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "\n",
    "    x_test = np.array(test_df['mfccs_stats'].to_list())\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2])\n",
    "\n",
    "    y_test = np.array(test_df['state_code'].to_list())\n",
    "    y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(num_classes):\n",
    "\n",
    "    # model = tf.keras.Sequential([tf.keras.layers.LSTM(256, return_sequences=False),\n",
    "    #                           tf.keras.layers.BatchNormalization(),\n",
    "    #                           tf.keras.layers.Dropout(0.4),\n",
    "    #                           tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(256, return_sequences=True),  # 첫 번째 LSTM 레이어\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "\n",
    "        tf.keras.layers.LSTM(128, return_sequences=False),  # 두 번째 LSTM 레이어\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=[\n",
    "                  'sparse_categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 16:06:11.544988: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-08 16:06:11.546949: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 16:06:11.703466: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-08-08 16:06:13.353851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:06:13.762730: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:06:14.129241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:06:14.542333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:06:15.032000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:06:17.179246: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:06:17.333011: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:06:17.422344: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb Cell 10\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_train, X_test, Y_train, Y_test \u001b[39m=\u001b[39m split_xy(train, test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m lstm_model \u001b[39m=\u001b[39m get_lstm_model(num_classes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m history \u001b[39m=\u001b[39m lstm_model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, epochs\u001b[39m=\u001b[39;49mEPOCHS, validation_data\u001b[39m=\u001b[39;49m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     X_test, Y_test), callbacks\u001b[39m=\u001b[39;49m[], verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m accuracy_score \u001b[39m=\u001b[39m lstm_model\u001b[39m.\u001b[39mevaluate(X_test, Y_test)\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_xy(train, test)\n",
    "\n",
    "lstm_model = get_lstm_model(num_classes=10)\n",
    "\n",
    "history = lstm_model.fit(X_train, Y_train, batch_size=128, epochs=EPOCHS, validation_data=(\n",
    "    X_test, Y_test), callbacks=[], verbose=0)\n",
    "\n",
    "accuracy_score = lstm_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "lstm_test_preds = lstm_model.predict(X_test)\n",
    "lstm_test_pred_classes = np.argmax(lstm_test_preds, axis=1)\n",
    "\n",
    "print(classification_report(Y_test, lstm_test_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
