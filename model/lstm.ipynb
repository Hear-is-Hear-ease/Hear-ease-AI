{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import sys\n",
    "\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import kurtosis, median_abs_deviation\n",
    "\n",
    "sys.path.append('/Users/jaewone/developer/tensorflow/baby-cry-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constant.os import *\n",
    "from utils.os import *\n",
    "from utils.sound import *\n",
    "from trans_data.get_state_list import get_state_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(file_path,\n",
    "             sampling_freq=16000,\n",
    "             mfcc_coef=40,\n",
    "             mfcc_coef_retain=25,\n",
    "             mfcc_window_duration=0.0232):\n",
    "    \"\"\"\n",
    "    오디오 파일에 대한 MFCC를 분석한 뒤 값을 반환한다.\n",
    "\n",
    "    Parameters:\n",
    "        file_path:            오디오 파일의 경로\n",
    "        sampling_freq:        sampling rate\n",
    "        mfcc_coef:            frame의 길이를 결정하는 파라미터.\n",
    "        mfcc_coef_retain:     유지되는 MFCC 값의 길이\n",
    "        mfcc_window_duration: 데이터를 읽을 때 겹쳐 읽는 길이(sec)\n",
    "\n",
    "    Returns:\n",
    "        list[0]: 초반 mfcc_coef_retain 만큼의 MFCC 값\n",
    "        list[1]: 평균, 분산, 표준편차와 같은 MFCC의 특성값\n",
    "    \"\"\"\n",
    "\n",
    "    # load wav file and normalize\n",
    "    wave, sr = librosa.load(file_path, mono=True, sr=sampling_freq)\n",
    "    wave = librosa.util.normalize(wave)\n",
    "\n",
    "    # feature extraction\n",
    "    \"\"\"\n",
    "    ① sr: sampling rate\n",
    "    ② n_mfcc=20 : mfcc의 개수\n",
    "    ③ n_fft=25\n",
    "        frame의 길이를 결정하는 파라미터 입니다. n_fft를 설정하면 window size가 자동으로 같은 값으로 설정되는데 window size의 크기로 잘린 음성이 n_fft보다 작은 경우 0으로 padding을 붙여주는 작업을 하기 때문에 n_fft는 window size보다 크거나 같아야 한다.\n",
    "        보통 n_fft = sr * frame_length 로 설정\n",
    "    ④ hop_length=10\n",
    "        hop_length의 길이만큼 옆으로 가면서 데이터를 읽는다. \n",
    "        10ms를 기본으로 하고 있어 16000Hz인 음성에서는 160에 해당한다. (16000 * 0.01 = 160)\n",
    "        보통 hop_length는 = sr * frame_stride 로 설정한다.\n",
    "    \"\"\"\n",
    "    mfccs = librosa.feature.mfcc(y=wave, sr=sr, n_mfcc=mfcc_coef, hop_length=int(\n",
    "        mfcc_window_duration*sr/2.0), n_fft=int(mfcc_window_duration*sr))\n",
    "\n",
    "    # 정규화: 평균이 0, 표준편차 1\n",
    "    mfccs = (mfccs - np.mean(mfccs))/np.std(mfccs)\n",
    "\n",
    "    # keep the first mfcc_coef_retain coefficients\n",
    "    \"\"\"\n",
    "    일부 계수를 폐기하는 이유는 무엇입니까? \n",
    "    일반적으로 하위 MFCC는 스펙트럼의 전체 모양에 대한 더 많은 정보를 포함하고(따라서 더 중요함) 상위 MFCC는 스펙트럼에서 더 미세한 세부 사항을 나타내기 시작합니다. \n",
    "    처음 25개의 MFCC만 유지하도록 선택함으로써 작성자는 마지막 15개의 계수(26에서 40까지)가 모델의 증가된 복잡성을 정당화할 만큼 중요한 정보를 충분히 전달하지 않는다고 결정했을 가능성이 큽니다.\n",
    "    즉, 유지할 MFCC 수의 선택은 문제에 따라 다를 수 있으며 다른 응용 프로그램이나 모델에는 다른 수가 필요할 수 있습니다. 일부 응용 프로그램의 경우 처음 13개의 계수만 사용되는 반면 \n",
    "    다른 응용 프로그램의 경우 40개 모두 사용될 수 있습니다. 주어진 작업에 대한 최적의 수를 찾으려면 종종 어느 정도의 실험이 필요합니다.\n",
    "    \"\"\"\n",
    "    mfccs = mfccs[:mfcc_coef_retain, :]\n",
    "\n",
    "    # calculate MFCC statistics\n",
    "    mfccs_min = mfccs.min(axis=1)\n",
    "    mfccs_max = mfccs.max(axis=1)\n",
    "    mfccs_median = np.median(mfccs, axis=1)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    mfccs_var = np.var(mfccs, axis=1)\n",
    "    mfccs_skewness = skew(mfccs, axis=1)\n",
    "    mfccs_kurtosis = kurtosis(mfccs, axis=1)\n",
    "    mfccs_mad = median_abs_deviation(mfccs, axis=1)\n",
    "\n",
    "    mfccs_first_derivative = np.diff(mfccs, n=1, axis=1)\n",
    "    mfccs_first_derivative_mean = np.mean(mfccs_first_derivative, axis=1)\n",
    "    mfccs_first_derivative_var = np.var(mfccs_first_derivative, axis=1)\n",
    "\n",
    "    mfccs_second_derivative = np.diff(mfccs, n=2, axis=1)\n",
    "    mfccs_second_derivative_mean = np.mean(mfccs_second_derivative, axis=1)\n",
    "    mfccs_second_derivative_var = np.var(mfccs_second_derivative, axis=1)\n",
    "\n",
    "    mfccs_stats = np.vstack((mfccs_min, mfccs_max, mfccs_median, mfccs_mean, mfccs_var, mfccs_skewness, mfccs_kurtosis, mfccs_mad,\n",
    "                            mfccs_first_derivative_mean, mfccs_first_derivative_var, mfccs_second_derivative_mean, mfccs_second_derivative_var))\n",
    "\n",
    "    return pd.Series([mfccs, mfccs_stats.transpose()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaewone/ENTER/envs/tf25/lib/python3.9/site-packages/numba/cpython/hashing.py:482: UserWarning: FNV hashing is not implemented in Numba. See PEP 456 https://www.python.org/dev/peps/pep-0456/ for rationale over not using FNV. Numba will continue to work, but hashes for built in types will be computed using siphash24. This will permit e.g. dictionaries to continue to behave as expected, however anything relying on the value of the hash opposed to hash as a derived property is likely to not work as expected.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>duration</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>uncomfortable_109.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>uncomfortable_135.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>uncomfortable_121.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  duration          state\n",
       "3777  uncomfortable_109.wav       5.0  uncomfortable\n",
       "3778  uncomfortable_135.wav       5.0  uncomfortable\n",
       "3779  uncomfortable_121.wav       5.0  uncomfortable"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = get_state_file_list(data_path)\n",
    "\n",
    "df = pd.DataFrame({'file':file_list})\n",
    "df['duration'] = df['file'].apply(lambda file: get_duration(file))\n",
    "df['file'] = df['file'].apply(lambda file: file.rsplit('/', 1)[1])\n",
    "df['state'] = df['file'].apply(lambda file: file.split('_', 1)[0]).astype('category')\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3780 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3780/3780 [00:29<00:00, 126.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>duration</th>\n",
       "      <th>state</th>\n",
       "      <th>mfccs</th>\n",
       "      <th>mfccs_stats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3777</th>\n",
       "      <td>uncomfortable_109.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>[[-5.220834, -6.01142, -6.1456327, -5.8742223,...</td>\n",
       "      <td>[[-8.55258, -3.0695317, -5.640008, -5.645126, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>uncomfortable_135.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>[[-3.8128958, -3.598897, -3.5140378, -3.429702...</td>\n",
       "      <td>[[-11.446929, -2.9981005, -4.655477, -5.477557...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3779</th>\n",
       "      <td>uncomfortable_121.wav</td>\n",
       "      <td>5.0</td>\n",
       "      <td>uncomfortable</td>\n",
       "      <td>[[-6.8476195, -6.789292, -6.7553797, -6.767772...</td>\n",
       "      <td>[[-7.3525023, -2.7414045, -5.8861413, -5.91529...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       file  duration          state  \\\n",
       "3777  uncomfortable_109.wav       5.0  uncomfortable   \n",
       "3778  uncomfortable_135.wav       5.0  uncomfortable   \n",
       "3779  uncomfortable_121.wav       5.0  uncomfortable   \n",
       "\n",
       "                                                  mfccs  \\\n",
       "3777  [[-5.220834, -6.01142, -6.1456327, -5.8742223,...   \n",
       "3778  [[-3.8128958, -3.598897, -3.5140378, -3.429702...   \n",
       "3779  [[-6.8476195, -6.789292, -6.7553797, -6.767772...   \n",
       "\n",
       "                                            mfccs_stats  \n",
       "3777  [[-8.55258, -3.0695317, -5.640008, -5.645126, ...  \n",
       "3778  [[-11.446929, -2.9981005, -4.655477, -5.477557...  \n",
       "3779  [[-7.3525023, -2.7414045, -5.8861413, -5.91529...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get MFCC data\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "df[['mfccs', 'mfccs_stats']] = df.progress_apply(lambda x: get_mfcc(os.path.join(data_path, x['state'], x['file'])), axis=1)\n",
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3780 entries, 0 to 3779\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   file         3780 non-null   object  \n",
      " 1   duration     3780 non-null   float64 \n",
      " 2   state        3780 non-null   category\n",
      " 3   mfccs        3780 non-null   object  \n",
      " 4   mfccs_stats  3780 non-null   object  \n",
      " 5   state_code   3780 non-null   int8    \n",
      "dtypes: category(1), float64(1), int8(1), object(3)\n",
      "memory usage: 126.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# state 열을 카테고리 타입으로 변환한 다음 int 형태로 캐스팅한다.\n",
    "df.state = df.state.astype('category')\n",
    "df = df.assign(state_code=df.state.cat.codes)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(train_df: pd.DataFrame, test_df:pd.DataFrame):\n",
    "    x_train = np.array(train_df['mfccs_stats'].to_list())\n",
    "    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2])\n",
    "\n",
    "    y_train = np.array(train_df['state_code'].to_list())\n",
    "    y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "\n",
    "    x_test = np.array(test_df['mfccs_stats'].to_list())\n",
    "    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2])\n",
    "\n",
    "    y_test = np.array(test_df['state_code'].to_list())\n",
    "    y_test = y_test.reshape(y_test.shape[0], 1)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lstm_model(num_classes):\n",
    "\n",
    "    # model = tf.keras.Sequential([tf.keras.layers.LSTM(256, return_sequences=False),\n",
    "    #                           tf.keras.layers.BatchNormalization(),\n",
    "    #                           tf.keras.layers.Dropout(0.4),\n",
    "    #                           tf.keras.layers.Dense(num_classes, activation='softmax')])\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(256, return_sequences=True),  # 첫 번째 LSTM 레이어\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "\n",
    "        tf.keras.layers.LSTM(128, return_sequences=False),  # 두 번째 LSTM 레이어\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='sparse_categorical_crossentropy', metrics=[\n",
    "                  'sparse_categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 16:26:32.471588: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-08 16:26:32.472100: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 16:26:32.595244: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-08-08 16:26:34.288577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:26:34.689584: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:26:34.858867: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:26:35.085858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:26:35.348894: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:26:36.955340: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:26:37.083064: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 16:26:37.163480: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb Cell 10\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X_train, X_test, Y_train, Y_test \u001b[39m=\u001b[39m split_xy(train, test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m lstm_model \u001b[39m=\u001b[39m get_lstm_model(num_classes\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m history \u001b[39m=\u001b[39m lstm_model\u001b[39m.\u001b[39;49mfit(X_train, Y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, epochs\u001b[39m=\u001b[39;49mEPOCHS, validation_data\u001b[39m=\u001b[39;49m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     X_test, Y_test), callbacks\u001b[39m=\u001b[39;49m[], verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jaewone/developer/tensorflow/baby-cry-classification/model/lstm.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m accuracy_score \u001b[39m=\u001b[39m lstm_model\u001b[39m.\u001b[39mevaluate(X_test, Y_test)\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/keras/engine/training.py:1376\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1374\u001b[0m callbacks\u001b[39m.\u001b[39mon_epoch_begin(epoch)\n\u001b[1;32m   1375\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m-> 1376\u001b[0m   \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[1;32m   1377\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m         epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m         step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m         _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m       callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/keras/engine/data_adapter.py:1246\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1244\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[1;32m   1245\u001b[0m   \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1246\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   1247\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[1;32m   1248\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m\n\u001b[1;32m   1251\u001b[0m     original_spe)\n\u001b[1;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/tensorflow/python/ops/resource_variable_ops.py:674\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 674\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    675\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    676\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1223\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \n\u001b[1;32m   1202\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1222\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1223\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/ENTER/envs/tf25/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1189\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1188\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1190\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_xy(train, test)\n",
    "\n",
    "lstm_model = get_lstm_model(num_classes=10)\n",
    "\n",
    "history = lstm_model.fit(X_train, Y_train, batch_size=128, epochs=EPOCHS, validation_data=(\n",
    "    X_test, Y_test), callbacks=[], verbose=0)\n",
    "\n",
    "accuracy_score = lstm_model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "lstm_test_preds = lstm_model.predict(X_test)\n",
    "lstm_test_pred_classes = np.argmax(lstm_test_preds, axis=1)\n",
    "\n",
    "print(classification_report(Y_test, lstm_test_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
